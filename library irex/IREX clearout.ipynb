{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959a9678",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# IREX: A reusable process for the iterative refinement and explanation of classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcbeebc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class IREX:\n",
    "    def __init__(self):\n",
    "        ## The names of the explanation methods used are defined.\n",
    "        name_methods = [\"Importance\", \"LIME\", \"SHAP\", \"ALE\"]\n",
    "\n",
    "    def load_dataset_from_csv(self, dataset_csv, dependant_variables_range = [0:-1], target_variable = [-1], target_names):\n",
    "        self.dataset_file = dataset_csv\n",
    "        self.df = pd.read_csv(path_dataset)\n",
    "        self.train_cols = df.columns.range(dependant_variables_range)\n",
    "        self.label = df.columns.range(target_variable)\n",
    "        self.X = df [self.train_cols]\n",
    "        self.y = df [self.label]\n",
    "        self.target_names = target_names\n",
    "    \n",
    "    def load_dataset(self, train_cols_dataframe, target_col_dataframe, target_names):\n",
    "        self.train_cols = train_cols_dataframe\n",
    "        self.label = target_col_dataframe\n",
    "        self.X = df [self.train_cols]\n",
    "        self.y = df [self.label] \n",
    "        self.target_names = target_names\n",
    "  \n",
    "    def load_expected_answers(csv_filename, item_column_index = 0, class_column_index = 1, expected_answer_index = 2):\n",
    "        #cargar scv y crear una función que devuelve el valor esperado dado el índice del item y la clase:\n",
    "        # el csv tiene: col0: item index, col1: class, col2: valoresperado\n",
    "        # def eaf(item,class): \n",
    "        self.eaf = eaf\n",
    "    \n",
    "    def set_expected_answers_function(function):\n",
    "        self.eaf = function\n",
    "    \n",
    "\n",
    "    def reset_IREX(self):\n",
    "        ## Generation of the question status list automatically.\n",
    "        question = list(range(1, self.train_cols.shape[1]))\n",
    "        status = ['In use' for _ in range(1, self.train_cols.shape[1])]\n",
    "        self.ds = pd.DataFrame({'Question': question, 'Status': status})\n",
    "\n",
    "        ## Save the changed statuses in the dataset.\n",
    "        self.ds.to_csv(path_dataset_qs, index = False)\n",
    "\n",
    "        ## Generation of the data structure by iteration automatically.\n",
    "        columns = ['Question', 'Acurracy global']\n",
    "\n",
    "        for index in range(0, len(name_class)):\n",
    "            columns.append('Precision_' + str(index))\n",
    "            columns.append('Recall_' + str(index))\n",
    "            columns.append('F1_score_' + str(index))\n",
    "            columns.append('Support_' + str(index))\n",
    "\n",
    "        self.dd = pd.DataFrame(columns = columns)\n",
    "\n",
    "        ## Save the changed data in the dataset.\n",
    "        self.dd.to_csv(path_dataset_qd, index = False)\n",
    "        \n",
    "        ## The number of iterations performed in the explanation is defined.\n",
    "        self.iteration = 0\n",
    "\n",
    "    def oversample():\n",
    "        ## The oversample function used is defined.\n",
    "        random_state = 13\n",
    "        oversample = SMOTE(random_state = random_state)\n",
    "        self.X, self.y = oversample.fit_resample(self.X, self.y)\n",
    "        \n",
    "    def train_model(do_oversample=true, test_size=0.33, hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = 1, \n",
    "             learning_rate = 'constant', learning_rate_init = 0.0001, max_iter = 100000, random_state = 77):\n",
    "        if(do_oversample):\n",
    "            oversamplle()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size, random_state=seed)\n",
    "        ## The value of the alpha parameter is kept at 1 as well as the value of the seed of random_state at 77.\n",
    "        self.mlp = MLPClassifier(hidden_layer_sizes, activation, solver, alpha, \n",
    "             learning_rate , learning_rate_init, max_iter0, random_state)\n",
    "\n",
    "        ## We print the data of the final generated model.\n",
    "        self.mlp.fit(self.X_train, self.y_train)\n",
    "    \n",
    "    def dump_model(filename):\n",
    "        joblib.dump(self.mlp, filename)\n",
    "        \n",
    "    def load_model(filename):\n",
    "        self.mlp = return joblib.load(filename)\n",
    "    \n",
    "    def evaluate_model():\n",
    "        ## The data for the generation of the confession matrix are defined.\n",
    "        confusion_matrix = ConfusionMatrixDisplay.from_estimator(self.mlp, self.X_test, self.y_test, display_labels = target_names,\n",
    "                                                         cmap = plt.cm.Blues)\n",
    "        confusion_matrix.ax_.set_title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "        \n",
    "        ## The necessary detailed prediction is generated.\n",
    "        y_pred = mlp.predict(self.X_test)\n",
    "\n",
    "        ## The detailed statistics of the model are printed.\n",
    "        print(classification_report(self.y_test,y_pred))\n",
    "        \n",
    "    def compute_explanation(PAI_significance_thresold = .1):\n",
    "        self.iteration++\n",
    "        __run_ALE()\n",
    "        __run_LIME()\n",
    "        __run_SHAP()\n",
    "        __run_Feature_Importance()\n",
    "        __compute_PAI(PAI_significance_thresold, selection_method = 1)#no liarse con esto. Hacer el más sencillo\n",
    "       \n",
    "    def __run_ALE():\n",
    "        #rellenar\n",
    "        #In analysis of the model through the results obtained by ALE, it is possible to identify the behavior\n",
    "        #of the neural network.\n",
    "        ## The necessary parameters for the use of ALE are established according to the model.\n",
    "        proba_fun_lr = mlp.predict_proba\n",
    "        proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "        proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())\n",
    "        plot_ale(proba_exp_lr, n_cols=2, features=list(range(df.shape[1]-1)),fig_kw={'figwidth': 10, 'figheight': 180});\n",
    "\n",
    "    def __run_LIME():\n",
    "        #rellenar\n",
    "        #We proceed to explain the improved model using LIME for the Low, Medium and High classes.\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                   feature_names=train_cols, class_names=target_names, \n",
    "                                                   discretize_continuous=True)\n",
    "        #The first individual present in the test data is explained.\n",
    "        exp = explainer.explain_instance(X_test.to_numpy()[0], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "        exp.show_in_notebook(show_table=True, show_all=False)\n",
    "        #The second individual present in the test data is explained.\n",
    "        exp = explainer.explain_instance(X_test.to_numpy()[1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "        exp.show_in_notebook(show_table=True, show_all=False)\n",
    "        #The last individual present in the test data is explained.\n",
    "        exp = explainer.explain_instance(X_test.to_numpy()[-1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "        exp.show_in_notebook(show_table=True, show_all=False)\n",
    "    def __run_SHAP():\n",
    "        #rellenar\n",
    "        #SHAP explanatory values are displayed according to the class to which the selected individual belongs according to the prediction of the model.\n",
    "        #The first individual present in the test data is explained.\n",
    "        ## Individual Selection.\n",
    "        individual = X_test.iloc[[0]]\n",
    "\n",
    "        ## Individual explanation by SHAP.\n",
    "        explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "        shap_values = explainer.shap_values(individual)\n",
    "        clase = mlp.predict(individual)[0]\n",
    "        shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")\n",
    "        #The second individual present in the data test is explained.\n",
    "        ## Individual Selection.\n",
    "        individual = X_test.iloc[[1]]\n",
    "\n",
    "        ## Individual explanation by SHAP.\n",
    "        explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "        shap_values = explainer.shap_values(individual)\n",
    "        clase = mlp.predict(individual)[0]\n",
    "        shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")\n",
    "        #The last individual present in the data test is explained.\n",
    "        ## Individual Selection.\n",
    "        individual = X_test.iloc[[-1]]\n",
    "\n",
    "        ## Individual explanation by SHAP.\n",
    "        explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "        shap_values = explainer.shap_values(individual)\n",
    "        clase = mlp.predict(individual)[0]\n",
    "        shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")\n",
    "    #def __run_Feature_Importance():\n",
    "        #rellenar\n",
    "    \n",
    "    #def __compute_PAI(selection_method = 1):\n",
    "        #rellenar\n",
    "        #según el número que pongan, es el método para determinar las PAIs (los 5 casos que nos dió juan)\n",
    "        \n",
    "    def visualize_global_heatmap(_class):\n",
    "        #según la clase, se tiene que visualizar el mapa de calor\n",
    "    \n",
    "    def visualize_class_heatmap(_class, XAI_method):\n",
    "        #según la clase que se elija y el método, se desplegará el mapa de calor solo de dicha clase\n",
    "        \n",
    "    def visualize_average_heatmap(XAI_method):\n",
    "        #\n",
    "    \n",
    "    def visualize_detailled_heatmap(XAI_method):\n",
    "        #\n",
    "        \n",
    "    def refine_dataset(anomalous_list):\n",
    "        # remove items from dataframes self.X self.y\n",
    "\n",
    "        \n",
    "    def plot_global_process(accuracy = true, precision = true, recall = true):\n",
    "        #todo\n",
    "        #depende de lo que elijan, que se despliegue el dato (aunque creo que con este codig no se puede)\n",
    "        #We get the detailed statistics of the final model.\n",
    "        ## The necessary detailed prediction is generated.\n",
    "        y_pred = mlp.predict(X_test)\n",
    "\n",
    "        ## The detailed statistics of the model are printed.\n",
    "        print('Classification accuracy =',accuracy_score(y_test,y_pred) * 100,'%\\n')\n",
    "        print(classification_report(y_test,y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92946646",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "irex = new IREX()\n",
    "irex.load_dataset_from_csv('file.csv', [:-1], [-1], [\"Low\",\"Mid\",\"High\"])\n",
    "irex.load_expected_answers('answers.csv')\n",
    "irex.reset()\n",
    "irex.oversample()\n",
    "irex.train()\n",
    "irex.evaluate_model()\n",
    "irex.compute_explanation()\n",
    "irex.visualize_global_heatmap(\"High\")\n",
    "irex.visualize_class_heatmap(\"High\",\"LIME\")\n",
    "irex.refine_dataset([2,7,9,3,13,34])\n",
    "\n",
    "irex.train()\n",
    "irex.evaluate_model()\n",
    "irex.compute_explanation()\n",
    "irex.visualize_global_heatmap(\"High\")\n",
    "irex.visualize_class_heatmap(\"High\",\"LIME\")\n",
    "irex.refine_dataset([2,7,9,3,13,34])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ef642",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661dabea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc9956c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import all necessary libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f11d8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Of the following imports, the most important libraries are: sklearn.neural_network and sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e2244",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import dice_ml\n",
    "import shap\n",
    "import lime\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from explainerdashboard import ClassifierExplainer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_recall_fscore_support, classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from alibi.explainers.ale import ALE, plot_ale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f2992a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Defining global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2ded77",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following variables defined below can be modified according to the given approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b60757e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The dataset is defined with the model to explain.\n",
    "path_dataset = \"Dataset_MO_ENG.csv\"\n",
    "\n",
    "## The dataset with the expected responses is defined.\n",
    "path_dataset_qa = \"Dataset_QA_ENG.csv\"\n",
    "\n",
    "## The column, shape and grouping name of the dataset to be explained are defined.\n",
    "grouping_name = 'Target' # *\n",
    "class_dic = {1: 0 , 2: 0, 3:1, 4:2, 5:2}\n",
    "\n",
    "## * If this data is None or empty string then class_dic will be ignored.\n",
    "\n",
    "## The class names present in the dataset to be explained are defined.\n",
    "target_names = [\"Low\", \"Medium\", \"High\"] # *\n",
    "\n",
    "## * If grouping_name is None or empty, then a class name must exist.\n",
    "##   If not, then the total class name must agree with the total groupings defined in class_dic.\n",
    "\n",
    "## The class names present in the dataset to be plotted are defined.\n",
    "name_class = [\"Class Low\", \"Class Medium\", \"Class High\"] # *\n",
    "list_color = ['gray', 'black', 'red']\n",
    "\n",
    "## * If grouping_name is None or empty, then a class name must exist.\n",
    "##   If not, then the total class name must agree with the total groupings defined in class_dic.\n",
    "\n",
    "## The items to exclude from the dataset are defined.\n",
    "unrelated_questions = [102, -1] # *\n",
    "\n",
    "## * If this data is an empty list then this data will be ignored.\n",
    "\n",
    "## The list of items eliminated at the start of the first iteration is defined.\n",
    "list_contr = [3, 4, 5, 14, 21, 24, 25, 26, 27, 29, 30, 32, 48, 49, 51, 54, 55,\n",
    "              58, 59, 60, 62, 63, 66, 68, 70, 75, 78, 83, 85, 86, 87, 89, 90,\n",
    "              91, 94, 95, 96, 98, 100, 101]\n",
    "\n",
    "## The regular and alpha parameters of the training are defined.\n",
    "regul_param_normal = 10.0 ** - np.arange(-2, 7)\n",
    "regul_param_alpha = 10.0 ** - np.arange(0, 7)\n",
    "\n",
    "## The alpha, random state and learning rate training parameters are defined for each iteration.\n",
    "learning_rate_init = 0.1\n",
    "random_state_model = 42\n",
    "alpha = 0.001\n",
    "\n",
    "## Positive and negative threshold values are defined for the slope qualification process.\n",
    "positive_threshold = 0.01\n",
    "negative_threshold = -0.01\n",
    "\n",
    "## The qualification mode of each answer obtained is defined.\n",
    "selection_mode = 1 # *\n",
    "\n",
    "## * The following modes are available for the qualification the answers present in the dataset:\n",
    "##\n",
    "##     1. Selection of a single class.\n",
    "##     2. Selection of multiple classes with OR type condition.\n",
    "##     3. Selection of multiple classes with AND type condition.\n",
    "##     4. Selection of multiple classes with AND type condition when they are Out-of-threshold range.\n",
    "\n",
    "## The position of the class to qualify is defined.\n",
    "select_class_mode = 2 # *\n",
    "\n",
    "## * Position is related to the number of classes present in target_names and is required only when\n",
    "##   selection_mode is set to 1.\n",
    "\n",
    "## The positions of the classes to qualify are defined.\n",
    "selection_class = [0, 2] # *\n",
    "\n",
    "## * Positions are related to the number of classes present in target_names and is required only when\n",
    "##   selection_mode is set to 2, 3 and 4.\n",
    "\n",
    "## The map of expected responses is defined.\n",
    "expected_response_map = [[0, 1, 0, 1], [1, 0, 1, 0]] # *\n",
    "## * A two-dimensional list is defined, where each element of is a list of 4 numerical elements limited\n",
    "##   to 0 and 1. The number of elements of this is given by the number of classes to qualify.\n",
    "## \n",
    "##   The 4 numerical elements must meet the following conditions:\n",
    "##\n",
    "##       Element 1. Score is 1 and expected response is 0.\n",
    "##       Element 2. Score is 1 and expected response is 1.\n",
    "##       Element 3. Score is 0 and expected response is 1.\n",
    "##       Element 4. Score is 0 and expected response 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd0e0e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Defining private variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84263cc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following variables defined below cannot be modified since they are an integral part of its operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5525e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The datasets for storing the auxiliary data are defined.\n",
    "path_dataset_qs = \"Dataset_QS_ENG.csv\"\n",
    "path_dataset_qd= \"Dataset_QD_ENG.csv\"\n",
    "\n",
    "## The oversample function used is defined.\n",
    "random_state = 13\n",
    "oversample = SMOTE(random_state = random_state)\n",
    "\n",
    "## The seed used for training the neural network is defined.\n",
    "seed = 1\n",
    "\n",
    "## The number of iterations performed in the explanation is defined.\n",
    "iteration = 0\n",
    "\n",
    "## The names of the explanation methods used are defined.\n",
    "name_methods = [\"Importance\", \"LIME\", \"SHAP\", \"ALE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fa0115",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing the data for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3533f4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data is prepared in order to be processed by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887337dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Loading data from the dataset.\n",
    "df = pd.read_csv(path_dataset)\n",
    "\n",
    "## Elimination of unrelated items from the dataset.\n",
    "if len(unrelated_questions) != 0:\n",
    "    df = df.drop(df.columns[unrelated_questions[0]:unrelated_questions[1]], axis=1)\n",
    "\n",
    "## Grouping of the target according to the defined dictionary.\n",
    "if grouping_name != None and grouping_name != '':\n",
    "    df[grouping_name] = df[grouping_name].map(class_dic)\n",
    "\n",
    "## Assignment of local variables according to the data necessary for the neural network.\n",
    "train_cols = df.columns [0:-1]\n",
    "label = df.columns [-1]\n",
    "X = df [train_cols]\n",
    "y = df [label]\n",
    "\n",
    "## Generation of the question status list automatically.\n",
    "question = list(range(1, df.shape[1]))\n",
    "status = ['In use' for _ in range(1, df.shape[1])]\n",
    "ds = pd.DataFrame({'Question': question, 'Status': status})\n",
    "\n",
    "## Save the changed statuses in the dataset.\n",
    "ds.to_csv(path_dataset_qs, index = False)\n",
    "\n",
    "## Generation of the data structure by iteration automatically.\n",
    "columns = ['Question', 'Acurracy global']\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    columns.append('Precision_' + str(index))\n",
    "    columns.append('Recall_' + str(index))\n",
    "    columns.append('F1_score_' + str(index))\n",
    "    columns.append('Support_' + str(index))\n",
    "\n",
    "dd = pd.DataFrame(columns = columns)\n",
    "\n",
    "## Save the changed data in the dataset.\n",
    "dd.to_csv(path_dataset_qd, index = False)\n",
    "\n",
    "## The prepared data of the dataset is printed.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc6e5d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Oversample application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df49e7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An oversample process is applied to level the amount of existing data given by the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97292545",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The number of elements present in the grouped target is printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e169a2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Oversample application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04417d7f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of the oversample to the prepared data.\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8567031a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Printing of the data after the application of the oversample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c0e35",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The results obtained after applying the oversample are printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1f6dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparation of the parameters of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9310bab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to define the parameters necessary for the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a9383",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb4eb9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab961a04",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The alpha parameters and the initial learning rate are adjusted to obtain the best performance with the model\n",
    "using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b6b84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_normal\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = regul_param, \n",
    "             learning_rate = 'constant', learning_rate_init = 0.0001, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1d09a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d191b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Alpha 10^{X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde8f63b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The training is performed again keeping the same parameters except for the alpha value that changes to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8531dc93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_alpha\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = 1, \n",
    "             learning_rate = 'constant', learning_rate_init = regul_param, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0976e25c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bdaccb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Learning Rate 10^{-X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc87d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be31266f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The parameters of the final model are modified according to the data obtained in the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3ae3d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The value of the alpha parameter is kept at 1 as well as the value of the seed of random_state at 77.\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = 1, \n",
    "             learning_rate = 'constant', learning_rate_init = 0.0001, max_iter = 100000, random_state = 77)\n",
    "\n",
    "## We print the data of the final generated model.\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f291f754",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We safeguard the final generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b47312",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(mlp,\"model_depression.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daef5f09",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the confusion matrix of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc52ea9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We obtain the statistics of the final model to generate its confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58ac32",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The data for the generation of the confession matrix are defined.\n",
    "confusion_matrix = ConfusionMatrixDisplay.from_estimator(mlp, X_test, y_test, display_labels = target_names,\n",
    "                                                         cmap = plt.cm.Blues)\n",
    "confusion_matrix.ax_.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d241bdeb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get the detailed statistics of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb65513",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary detailed prediction is generated.\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "## The detailed statistics of the model are printed.\n",
    "print('Classification accuracy =',accuracy_score(y_test,y_pred) * 100,'%\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b0bb6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model explainability process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305db11b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data used for the test of the neural network model is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca304f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e50a6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44030bc8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In analysis of the model through the results obtained by ALE, it is possible to identify the behavior of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb2661",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f5c29",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graphs of all the data present in the dataset used are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86661d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ale(proba_exp_lr, n_cols=2, features=list(range(df.shape[1]-1)),fig_kw={'figwidth': 10, 'figheight': 180});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6007eb65",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b69be7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to explain the improved model using LIME for the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf1d7a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                   feature_names=train_cols, class_names=target_names, \n",
    "                                                   discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e0476",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c7a4f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[0], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c02939",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d8aa1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d457df",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c24c7b",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[-1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9deef1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c593fa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SHAP explanatory values are displayed according to the class to which the selected individual belongs according to the prediction of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a37a009",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d461ebbb",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[0]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023580ea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd0808",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc346d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4e03a",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[-1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a62ca4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation using heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d3553",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The importance of the data present in the neural network is shown from explanation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f352f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The question status dataset is loaded.\n",
    "ds = pd.read_csv(path_dataset_qs)\n",
    "\n",
    "## Items currently in use are retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"].reset_index(drop=True)\n",
    "\n",
    "## The data is prepared for the generation of heatmaps.\n",
    "column_Map = ds_item['Question'].tolist()\n",
    "content_Map = [False for x in range(1, df.shape[1])]\n",
    "\n",
    "## The next items to be deleted will be marked.\n",
    "for index in range(0, len(content_Map)):\n",
    "    \n",
    "    if iteration == 0:\n",
    "        for delete in list_contr:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "    else:\n",
    "        for delete in question_anomaly:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "\n",
    "## The dataframe is created with the prepared data.\n",
    "df_mask = pd.DataFrame([content_Map], columns = column_Map)\n",
    "df_mask_imp = pd.concat([df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "df_mask_all = pd.concat([df_mask, df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "\n",
    "df_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9652349",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33c1630",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Identification of feature variables from the randomness of the answers as items of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1704017b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Loading the data for explainability.\n",
    "explainer = ClassifierExplainer(mlp, X_test, y_test)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9d37dd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e88c24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eddd11",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6afe25",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e33849a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b37953",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56d8c2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc78c4",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_importance = pd.concat(map_class, axis=1)\n",
    "df_importance.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Reds\", cbar = False)\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Blues\",yticklabels = True, xticklabels = True ,mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496cbfde",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ec53bb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9694e2b0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbef818",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112da716",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e6ad46",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1000b9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ebe16a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aadc36",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e2d8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a408fa2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6552d13e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a3c0d3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f7bc5c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64453412",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa38a8fb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b2298",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f326e746",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1feecf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f56ae2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8240c64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fcfb1d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9ea382",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2ca3d",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeed2f5a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e331c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f85e153",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f95ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42ea94",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89c02e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3822e73",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657cb827",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_shap = pd.concat(map_class, axis=1)\n",
    "df_shap.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ffee6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb41e3e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28caaa3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data preparation for explainability.\n",
    "lime_exp = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                  feature_names=train_cols, class_names=target_names,\n",
    "                                                  discretize_continuous=True)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdb70e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by LIME about the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81bb432",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for LIME array data.\n",
    "exp_matrix = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for LIME.\n",
    "for x in X_test.to_numpy():\n",
    "    \n",
    "    ## Auxiliary temporary variables.\n",
    "    exp_list = [[] for _ in range(len(name_class))]\n",
    "    \n",
    "    ## Loading the data for explainability.\n",
    "    exp = lime_exp.explain_instance(x, mlp.predict_proba, num_features = df.shape[1] - 1, top_labels = len(name_class))\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "        temp = exp.as_map()[elements]\n",
    "        temp.sort(key=itemgetter(0))\n",
    "        \n",
    "        ## Saving data of the Low, Medium and High classes.\n",
    "        for tup in temp:\n",
    "            exp_list[elements].append(tup[1])\n",
    "            \n",
    "        exp_matrix[elements].append(exp_list[elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ade63",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff3345d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f90bdf1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b866c67b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c86410",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783dbebd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980bb71",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df41c8dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62b3680",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639622e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704f0c15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796de1e1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb68295",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba474864",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34413d21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3005f283",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857ce61",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_lime = pd.concat(map_class, axis=1)\n",
    "df_lime.columns = name_class\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6720cc64",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01c127",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It shows the main effect of each question compared to the probability that the model predicts in each class. This effect is shown for both responses. Since there are only 2 answers, the map is the same but with the colors reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab4d18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names=train_cols, target_names= target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0aa397",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by ALE about all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e16c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for ALE array data.\n",
    "ale_list = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for ALE.\n",
    "for array in proba_exp_lr.ale_values:\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "    \n",
    "        ## Saving data of all the classes.\n",
    "        ale_list[elements].append(array[0][elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1d4b9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data processing for the explainability of ALE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8093ff1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data processing of the Low, Medium and High classes.\n",
    "for elements in range(0, len(name_class)):\n",
    "    ale_df = pd.DataFrame([ale_list [elements]])\n",
    "    ale_df = pd.concat([ale_df.multiply(-1), ale_df])\n",
    "    ale_df.index = [name_class [elements] + \" - False\", name_class [elements] + \" - True\"]\n",
    "    ale_df.columns = column_Map\n",
    "    map_class.append(ale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3100f3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddcf0d8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003e17f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e0b08",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a252a8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37680ab1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b221ded",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea525a00",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f56c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f9c916",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff01a88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of absolute value to data.\n",
    "for index in range(0, len(map_class)):\n",
    "    map_class [index] = map_class [index][0:1].abs()\n",
    "\n",
    "## Union of the heatmaps of the Low, Medium and High class.\n",
    "ale_df = pd.concat(map_class)\n",
    "ale_df.index = name_class\n",
    "ale_df = ale_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e549c02",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81ec98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask= df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10914e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparing of Feature Variables Methods for Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3515afff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The global values of each of the methods used are taken, their maximums are obtained (the minimums are 0) and a percentage is calculated based on said maximum, which indicates how relevant the contribution is for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23a7d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d44e54",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46094b7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75faa579",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c12f3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe80b6f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e97426",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62479b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9100ee0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c8e6ba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c398a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5618ffce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e95b91",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290219fc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f2c2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f19af1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df760d31",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3340826f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff45a5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55941a05",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134bdc2d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad32e0c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780d8b34",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural network model improvement iterative process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2a929e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From this moment, we proceed to improve the performance of the neural network to predict high depression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a10b7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iteration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ae5478",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first iteration of improvement of the model is carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316a8ab4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing the data for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907e201",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data is prepared in order to be processed by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7f86d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The iteration number is increased.\n",
    "iteration += 1\n",
    "\n",
    "## Loading data from the dataset.\n",
    "df = pd.read_csv(path_dataset)\n",
    "ds = pd.read_csv(path_dataset_qs)\n",
    "\n",
    "## Elimination of unrelated items from the dataset.\n",
    "if len(unrelated_questions) != 0:\n",
    "    df = df.drop(df.columns[unrelated_questions[0]:unrelated_questions[1]], axis=1)\n",
    "\n",
    "i = 0\n",
    "if iteration == 1:\n",
    "    ## Elimination of list of conflicting items declared in global variables.\n",
    "    for x in list_contr:\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "        ## Status change of the deleted question in the respective auxiliary dataset.\n",
    "        ds.loc[x - 1,'Status'] = 'Delete'\n",
    "    \n",
    "else:    \n",
    "    ## Elimination of the list of anomadic items defined in the improvement process.\n",
    "    ds_delete = ds[ds.Status == \"Delete\"].reset_index(drop=True)\n",
    "    for x in ds_delete['Question'].tolist():\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "\n",
    "## Grouping of the target according to the defined dictionary.\n",
    "if grouping_name != None and grouping_name != '':\n",
    "    df[grouping_name] = df[grouping_name].map(class_dic)\n",
    "\n",
    "## Assignment of local variables according to the data necessary for the neural network.\n",
    "train_cols = df.columns [0:-1]\n",
    "label = df.columns [-1]\n",
    "X = df [train_cols]\n",
    "y = df [label]\n",
    "\n",
    "## The prepared data of the dataset is printed.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6d38e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Oversample application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d370d4a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An oversample process is applied to level the amount of existing data given by the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f632f991",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The number of elements present in the grouped target is printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a231a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Oversample application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca07abf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of the oversample to the prepared data.\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2107166",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Printing of the data after the application of the oversample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0c787b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The results obtained after applying the oversample are printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85e4b4e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparation of the parameters of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26a1ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to define the parameters necessary for the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f4850",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10229fbf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c339303",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The alpha parameters and the initial learning rate are adjusted to obtain the best performance with the model\n",
    "using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fbb9d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_normal\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = regul_param, \n",
    "             learning_rate = 'constant', learning_rate_init = 0.0001, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36e5f6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be340ce1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Alpha 10^{X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37820b1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The training is performed again keeping the same parameters except for the alpha value that changes to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f071756",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_alpha\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = 1, \n",
    "             learning_rate = 'constant', learning_rate_init = regul_param, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057cca78",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808321ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Learning Rate 10^{-X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee37285",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530bd642",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The parameters of the final model are modified according to the data obtained in the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f786138",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The value of the alpha parameter, learning_rate_init and random_state are changed according\n",
    "## to the data in the global variables.\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = alpha,\n",
    "                            learning_rate = 'constant', learning_rate_init = learning_rate_init, max_iter = 100000,\n",
    "                            random_state = random_state_model)\n",
    "\n",
    "## We print the data of the final generated model.\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f480c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We safeguard the final generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36048ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(mlp,\"model_depression_i\" + str(iteration) + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a29d47",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the confusion matrix of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a7818",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We obtain the statistics of the final model to generate its confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18454b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The data for the generation of the confession matrix are defined.\n",
    "confusion_matrix = ConfusionMatrixDisplay.from_estimator(mlp, X_test, y_test, display_labels = target_names,\n",
    "                                                         cmap = plt.cm.Blues)\n",
    "confusion_matrix.ax_.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d25f05e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get the detailed statistics of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09abdc1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary detailed prediction is generated.\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "## The detailed statistics of the model are printed.\n",
    "print('Classification accuracy =',accuracy_score(y_test,y_pred) * 100,'%\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50cb502",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data obtained is saved for later graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0a9d1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred) * 100\n",
    "clf_rep = precision_recall_fscore_support(y_test,y_pred)\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_delete = ds[ds.Status == \"Delete\"]\n",
    "ds_delete.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## All the metrics of the confusion matrix are obtained.\n",
    "metrics = [\",\".join(map(str, ds_delete['Question'].tolist())),\n",
    "           accuracy]\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    metrics.append(clf_rep[0][index])\n",
    "    metrics.append(clf_rep[1][index])\n",
    "    metrics.append(clf_rep[2][index])\n",
    "    metrics.append(clf_rep[3][index])\n",
    "\n",
    "## The names of the columns of the dataset are defined.\n",
    "columns = ['Question', 'Acurracy global']\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    columns.append('Precision_' + str(index))\n",
    "    columns.append('Recall_' + str(index))\n",
    "    columns.append('F1_score_' + str(index))\n",
    "    columns.append('Support_' + str(index))\n",
    "\n",
    "## A new row of the dataset is generated with all the data.\n",
    "data_metrics = pd.DataFrame([metrics], columns = columns)\n",
    "\n",
    "## The data is saved to the dataset.\n",
    "data_metrics.to_csv(path_dataset_qd, mode = 'a', header = False, index = False)\n",
    "\n",
    "## The data added to the dataset is printed.\n",
    "data_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb03999",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Improvement process of the neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f919fda",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The application of the explanation method by ALE allows to determine the behavior of the neural network and thereby improve it by discarding non-significant data for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55286a57",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope Analysis of ALE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270e3bce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c19cd6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to obtain the graphs to obtain the slopes of the selected classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36dc41b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The question metrics dataset is loaded.\n",
    "dm = pd.DataFrame()\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"]\n",
    "ds_item.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## We get the slopes from the ALE data.\n",
    "for i in range(df.shape[1]-1):\n",
    "    structure_data = {'Question': ds_item.loc[i, \"Question\"]}\n",
    "    \n",
    "    for index in selection_class:\n",
    "        slope = proba_exp_lr.ale_values [i][1][index] - proba_exp_lr.ale_values [i][0][index]\n",
    "        structure_data['Slope ' + str(target_names[index])] = slope\n",
    "        structure_data['Threshold ' + str(target_names[index])] = 'NA'\n",
    "        structure_data['Anomaly ' + str(target_names[index])] = 'NA'\n",
    "        \n",
    "    dm = dm.append(structure_data, ignore_index=True)\n",
    "    \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a90cde6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope analysis and threshold application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efbc500",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The slope obtained is analyzed and those that are above or below the positive and negative threshold are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552b84f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## The slopes are selected according to the values of the thresholds of the defined classes.\n",
    "        if dm.loc[i, \"Slope \" + str(target_names[index])] >= positive_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 1\n",
    "        elif dm.loc[i, \"Slope \" + str(target_names[index])] <= negative_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 0\n",
    "            \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6965cce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis and determination of anomalous items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a83b4a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The anomalous items present in the model are determined based on their slope and expected response from the expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5db48b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The dataset of expected responses is loaded.\n",
    "da = pd.read_csv(path_dataset_qa)\n",
    "\n",
    "## Delete list of items deleted in this iteration.\n",
    "i = 0\n",
    "for x in ds_delete['Question']:\n",
    "    da.drop(da.index[x - (i + 1)], axis = 0, inplace = True)\n",
    "    i += 1\n",
    "\n",
    "## Indexes are restored for later use.\n",
    "da.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## The dataset of expected responses is printed.\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bf014d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to identify the anomadic items present in the model present in this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18962fef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    \n",
    "    ## Local variable to indicate the index of the selected classes.\n",
    "    i_index = 0\n",
    "    \n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## Determine if it fails based on the expected response parameters of the defined classes.\n",
    "        if dm.loc[i, \"Threshold \"  + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][0]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][1]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][2]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \"  + str(target_names[index])] = expected_response_map[i_index][3]\n",
    "        \n",
    "        ## Increase of the index of the selected classes.\n",
    "        i_index += 1\n",
    "\n",
    "## The final grade data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01544ea3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Removing identified anomadic items from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2f198",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to eliminate the identified anomadic items so as not to use them in the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b065c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variable for the elimination of the anomaly items.\n",
    "instructions = ''\n",
    "init = False\n",
    "question_anomaly = []\n",
    "\n",
    "if selection_mode == 1:\n",
    "    \n",
    "    ## Items that fail in the defined class are retrieved.\n",
    "    dm_delete = dm[dm['Anomaly ' + str(target_names[select_class_mode])] == 1]\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 2:\n",
    "    \n",
    "    ## Items that fail in classes defined with the or condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" or `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 3:\n",
    "    \n",
    "    ## Items that fail in classes defined with the and condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 4:\n",
    "    \n",
    "    ## Out-of-threshold items are retrieved in classes defined with the condition type and.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "\n",
    "## The selected blank items are printed according to the selection_mode.\n",
    "question_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e0b72",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model explainability process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8101d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data used for the test of the neural network model is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c4882",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b0f32",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc63613",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In analysis of the model through the results obtained by ALE, it is possible to identify the behavior of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf85e54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2efd4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graphs of all the data present in the dataset used are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2cc25f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ale(proba_exp_lr, n_cols=2, features=list(range(df.shape[1]-1)),fig_kw={'figwidth': 10, 'figheight': 180});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35e8b1b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef7b17c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to explain the improved model using LIME for the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a94d17",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                   feature_names=train_cols, class_names=target_names, \n",
    "                                                   discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368fa8ae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a122ee0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[0], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e2ca5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0319296",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6983d6d6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc7d11e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[-1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e856fc7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b82be",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SHAP explanatory values are displayed according to the class to which the selected individual belongs according to the prediction of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d479690",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56426fb3",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[0]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472c4442",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0265c99",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea4611",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f15eb",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[-1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed9047d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation using heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae82911",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The importance of the data present in the neural network is shown from explanation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1984c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Items currently in use are retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"].reset_index(drop=True)\n",
    "\n",
    "## The data is prepared for the generation of heatmaps.\n",
    "column_Map = ds_item['Question'].tolist()\n",
    "content_Map = [False for x in range(1, df.shape[1])]\n",
    "\n",
    "## The next items to be deleted will be marked.\n",
    "for index in range(0, len(content_Map)):\n",
    "    \n",
    "    if iteration == 0:\n",
    "        for delete in list_contr:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "    else:\n",
    "        for delete in question_anomaly:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "\n",
    "## The dataframe is created with the prepared data.\n",
    "df_mask = pd.DataFrame([content_Map], columns = column_Map)\n",
    "df_mask_imp = pd.concat([df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "df_mask_all = pd.concat([df_mask, df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "\n",
    "df_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5769b288",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68e62e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Identification of feature variables from the randomness of the answers as items of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8331bc6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Loading the data for explainability.\n",
    "explainer = ClassifierExplainer(mlp, X_test, y_test)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee47f18",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc73f3a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbfaba6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe783098",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74569393",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9e4c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f253fde",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c9d931",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_importance = pd.concat(map_class, axis=1)\n",
    "df_importance.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Reds\", cbar = False)\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Blues\",yticklabels = True, xticklabels = True ,mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d061d80",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54388c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593ea8f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9616be",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd9890",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494ea3f",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9737a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85fa605",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b30387",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a05fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4df1c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5187cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a22b0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24553812",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fbb203",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99f15f2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff652c26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81537c90",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983985a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ccdd78",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ef3e81",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1224682f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092accd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fafe2fa",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37d66ed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636fca9f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa3af6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8858065",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eebaae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1324a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f98502",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aa318c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_shap = pd.concat(map_class, axis=1)\n",
    "df_shap.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a0819",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb7e34d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad0719f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data preparation for explainability.\n",
    "lime_exp = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                  feature_names=train_cols, class_names=target_names,\n",
    "                                                  discretize_continuous=True)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b020d0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by LIME about the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc752052",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for LIME array data.\n",
    "exp_matrix = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for LIME.\n",
    "for x in X_test.to_numpy():\n",
    "    \n",
    "    ## Auxiliary temporary variables.\n",
    "    exp_list = [[] for _ in range(len(name_class))]\n",
    "    \n",
    "    ## Loading the data for explainability.\n",
    "    exp = lime_exp.explain_instance(x, mlp.predict_proba, num_features = df.shape[1] - 1, top_labels = len(name_class))\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "        temp = exp.as_map()[elements]\n",
    "        temp.sort(key=itemgetter(0))\n",
    "        \n",
    "        ## Saving data of the Low, Medium and High classes.\n",
    "        for tup in temp:\n",
    "            exp_list[elements].append(tup[1])\n",
    "            \n",
    "        exp_matrix[elements].append(exp_list[elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db40ed63",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc43df",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e01b4ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14647605",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d137291",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e6a40",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2eda7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c0156",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff41cb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6db5b0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235cadff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8105a33",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427239df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34615a31",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fcd761",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fb11cd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9abcef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_lime = pd.concat(map_class, axis=1)\n",
    "df_lime.columns = name_class\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfc56dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b17102d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It shows the main effect of each question compared to the probability that the model predicts in each class. This effect is shown for both responses. Since there are only 2 answers, the map is the same but with the colors reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2621e16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names=train_cols, target_names= target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3035ff8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by ALE about all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2498319a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for ALE array data.\n",
    "ale_list = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for ALE.\n",
    "for array in proba_exp_lr.ale_values:\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "    \n",
    "        ## Saving data of all the classes.\n",
    "        ale_list[elements].append(array[0][elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15444940",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data processing for the explainability of ALE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb9244",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data processing of the Low, Medium and High classes.\n",
    "for elements in range(0, len(name_class)):\n",
    "    ale_df = pd.DataFrame([ale_list [elements]])\n",
    "    ale_df = pd.concat([ale_df.multiply(-1), ale_df])\n",
    "    ale_df.index = [name_class [elements] + \" - False\", name_class [elements] + \" - True\"]\n",
    "    ale_df.columns = column_Map\n",
    "    map_class.append(ale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b42d30",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9083519f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae764d77",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c85956a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceca262",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca83e92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f33350",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e640ddf4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067e267",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f34d1c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b33be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of absolute value to data.\n",
    "for index in range(0, len(map_class)):\n",
    "    map_class [index] = map_class [index][0:1].abs()\n",
    "\n",
    "## Union of the heatmaps of the Low, Medium and High class.\n",
    "ale_df = pd.concat(map_class)\n",
    "ale_df.index = name_class\n",
    "ale_df = ale_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d493a68",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6750584",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask= df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c2f416",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparing of Feature Variables Methods for Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8439c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The global values of each of the methods used are taken, their maximums are obtained (the minimums are 0) and a percentage is calculated based on said maximum, which indicates how relevant the contribution is for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a63882",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493c0a1e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7b1c20",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01986f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f05171c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cbe334",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e3702",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1bad39",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b83868",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b01a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440e05d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8960074f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916cc794",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3623e94f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c526dc0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae974268",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801aeb49",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5dbf59",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6d2da5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49f51a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151b572f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92043fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a0493b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Safeguarding the items eliminated during this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e73f03",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Removal of anomalous items selected by selection_mode.\n",
    "for x in question_anomaly:\n",
    "\n",
    "    ## Status change of the deleted items in the respective auxiliary dataset.\n",
    "    ds.loc[x - 1,'Status'] = 'Delete'\n",
    "\n",
    "## Save the changed statuses in the dataset.\n",
    "ds.to_csv(path_dataset_qs, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae816c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iteration 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6798368b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first iteration of improvement of the model is carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb7129b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing the data for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2846c4b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data is prepared in order to be processed by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d630ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The iteration number is increased.\n",
    "iteration += 1\n",
    "\n",
    "## Loading data from the dataset.\n",
    "df = pd.read_csv(path_dataset)\n",
    "ds = pd.read_csv(path_dataset_qs)\n",
    "\n",
    "## Elimination of unrelated items from the dataset.\n",
    "if len(unrelated_questions) != 0:\n",
    "    df = df.drop(df.columns[unrelated_questions[0]:unrelated_questions[1]], axis=1)\n",
    "\n",
    "i = 0\n",
    "if iteration == 1:\n",
    "    ## Elimination of list of conflicting items declared in global variables.\n",
    "    for x in list_contr:\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "        ## Status change of the deleted question in the respective auxiliary dataset.\n",
    "        ds.loc[x - 1,'Status'] = 'Delete'\n",
    "    \n",
    "else:    \n",
    "    ## Elimination of the list of anomadic items defined in the improvement process.\n",
    "    ds_delete = ds[ds.Status == \"Delete\"].reset_index(drop=True)\n",
    "    for x in ds_delete['Question'].tolist():\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "\n",
    "## Grouping of the target according to the defined dictionary.\n",
    "if grouping_name != None and grouping_name != '':\n",
    "    df[grouping_name] = df[grouping_name].map(class_dic)\n",
    "\n",
    "## Assignment of local variables according to the data necessary for the neural network.\n",
    "train_cols = df.columns [0:-1]\n",
    "label = df.columns [-1]\n",
    "X = df [train_cols]\n",
    "y = df [label]\n",
    "\n",
    "## The prepared data of the dataset is printed.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97747a71",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Oversample application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c92b7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An oversample process is applied to level the amount of existing data given by the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7826a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The number of elements present in the grouped target is printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d310d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Oversample application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d226ddea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of the oversample to the prepared data.\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ea0ba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Printing of the data after the application of the oversample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ae8f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The results obtained after applying the oversample are printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89780d5c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparation of the parameters of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e246f245",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to define the parameters necessary for the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da57957",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c530a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d8387",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The alpha parameters and the initial learning rate are adjusted to obtain the best performance with the model\n",
    "using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b3986",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_normal\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = regul_param, \n",
    "             learning_rate = 'constant', learning_rate_init = 0.0001, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455f3c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91716ddb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Alpha 10^{X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b5079",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The training is performed again keeping the same parameters except for the alpha value that changes to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fb10b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_alpha\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = 1, \n",
    "             learning_rate = 'constant', learning_rate_init = regul_param, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a6aac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6283c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Learning Rate 10^{-X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b92d4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d9212",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The parameters of the final model are modified according to the data obtained in the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5502bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The value of the alpha parameter, learning_rate_init and random_state are changed according\n",
    "## to the data in the global variables.\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = alpha,\n",
    "                            learning_rate = 'constant', learning_rate_init = learning_rate_init, max_iter = 100000,\n",
    "                            random_state = random_state_model)\n",
    "\n",
    "## We print the data of the final generated model.\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe90e16",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We safeguard the final generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4dcb1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(mlp,\"model_depression_i\" + str(iteration) + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339cc3cd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the confusion matrix of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268a7f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We obtain the statistics of the final model to generate its confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a01c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The data for the generation of the confession matrix are defined.\n",
    "confusion_matrix = ConfusionMatrixDisplay.from_estimator(mlp, X_test, y_test, display_labels = target_names,\n",
    "                                                         cmap = plt.cm.Blues)\n",
    "confusion_matrix.ax_.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54275d8c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get the detailed statistics of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254ff7e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary detailed prediction is generated.\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "## The detailed statistics of the model are printed.\n",
    "print('Classification accuracy =',accuracy_score(y_test,y_pred) * 100,'%\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4986c5f8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data obtained is saved for later graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e1d464",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred) * 100\n",
    "clf_rep = precision_recall_fscore_support(y_test,y_pred)\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_delete = ds[ds.Status == \"Delete\"]\n",
    "ds_delete.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## All the metrics of the confusion matrix are obtained.\n",
    "metrics = [\",\".join(map(str, ds_delete['Question'].tolist())),\n",
    "           accuracy]\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    metrics.append(clf_rep[0][index])\n",
    "    metrics.append(clf_rep[1][index])\n",
    "    metrics.append(clf_rep[2][index])\n",
    "    metrics.append(clf_rep[3][index])\n",
    "\n",
    "## The names of the columns of the dataset are defined.\n",
    "columns = ['Question', 'Acurracy global']\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    columns.append('Precision_' + str(index))\n",
    "    columns.append('Recall_' + str(index))\n",
    "    columns.append('F1_score_' + str(index))\n",
    "    columns.append('Support_' + str(index))\n",
    "\n",
    "## A new row of the dataset is generated with all the data.\n",
    "data_metrics = pd.DataFrame([metrics], columns = columns)\n",
    "\n",
    "## The data is saved to the dataset.\n",
    "data_metrics.to_csv(path_dataset_qd, mode = 'a', header = False, index = False)\n",
    "\n",
    "## The data added to the dataset is printed.\n",
    "data_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c07593",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Improvement process of the neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7343f33f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The application of the explanation method by ALE allows to determine the behavior of the neural network and thereby improve it by discarding non-significant data for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a427f18b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope Analysis of ALE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf29210",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16028ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to obtain the graphs to obtain the slopes of the selected classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a266b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The question metrics dataset is loaded.\n",
    "dm = pd.DataFrame()\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"]\n",
    "ds_item.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## We get the slopes from the ALE data.\n",
    "for i in range(df.shape[1]-1):\n",
    "    structure_data = {'Question': ds_item.loc[i, \"Question\"]}\n",
    "    \n",
    "    for index in selection_class:\n",
    "        slope = proba_exp_lr.ale_values [i][1][index] - proba_exp_lr.ale_values [i][0][index]\n",
    "        structure_data['Slope ' + str(target_names[index])] = slope\n",
    "        structure_data['Threshold ' + str(target_names[index])] = 'NA'\n",
    "        structure_data['Anomaly ' + str(target_names[index])] = 'NA'\n",
    "        \n",
    "    dm = dm.append(structure_data, ignore_index=True)\n",
    "    \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf35de6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope analysis and threshold application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a078ec80",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The slope obtained is analyzed and those that are above or below the positive and negative threshold are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d83f052",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## The slopes are selected according to the values of the thresholds of the defined classes.\n",
    "        if dm.loc[i, \"Slope \" + str(target_names[index])] >= positive_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 1\n",
    "        elif dm.loc[i, \"Slope \" + str(target_names[index])] <= negative_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 0\n",
    "            \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ec244",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis and determination of anomalous items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5acfa3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The anomalous items present in the model are determined based on their slope and expected response from the expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a247de51",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The dataset of expected responses is loaded.\n",
    "da = pd.read_csv(path_dataset_qa)\n",
    "\n",
    "## Delete list of items deleted in this iteration.\n",
    "i = 0\n",
    "for x in ds_delete['Question']:\n",
    "    da.drop(da.index[x - (i + 1)], axis = 0, inplace = True)\n",
    "    i += 1\n",
    "\n",
    "## Indexes are restored for later use.\n",
    "da.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## The dataset of expected responses is printed.\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fccbdfe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to identify the anomadic items present in the model present in this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8c3c5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    \n",
    "    ## Local variable to indicate the index of the selected classes.\n",
    "    i_index = 0\n",
    "    \n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## Determine if it fails based on the expected response parameters of the defined classes.\n",
    "        if dm.loc[i, \"Threshold \"  + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][0]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][1]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][2]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \"  + str(target_names[index])] = expected_response_map[i_index][3]\n",
    "        \n",
    "        ## Increase of the index of the selected classes.\n",
    "        i_index += 1\n",
    "\n",
    "## The final grade data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca9ecfd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Removing identified anomadic items from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deed2947",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to eliminate the identified anomadic items so as not to use them in the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75664aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variable for the elimination of the anomaly items.\n",
    "instructions = ''\n",
    "init = False\n",
    "question_anomaly = []\n",
    "\n",
    "if selection_mode == 1:\n",
    "    \n",
    "    ## Items that fail in the defined class are retrieved.\n",
    "    dm_delete = dm[dm['Anomaly ' + str(target_names[select_class_mode])] == 1]\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 2:\n",
    "    \n",
    "    ## Items that fail in classes defined with the or condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" or `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 3:\n",
    "    \n",
    "    ## Items that fail in classes defined with the and condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 4:\n",
    "    \n",
    "    ## Out-of-threshold items are retrieved in classes defined with the condition type and.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "\n",
    "## The selected blank items are printed according to the selection_mode.\n",
    "question_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e9ce7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model explainability process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f6e6a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data used for the test of the neural network model is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3154f57",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df8c33c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8015636",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In analysis of the model through the results obtained by ALE, it is possible to identify the behavior of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0f71b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246c239",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graphs of all the data present in the dataset used are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cfe0ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ale(proba_exp_lr, n_cols=2, features=list(range(df.shape[1]-1)),fig_kw={'figwidth': 10, 'figheight': 180});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda82ad",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36607d65",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to explain the improved model using LIME for the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7615bdb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                   feature_names=train_cols, class_names=target_names, \n",
    "                                                   discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383ddcd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc963f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[0], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc7df23",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792212ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c4776",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb18f58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[-1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284842fe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108bd723",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SHAP explanatory values are displayed according to the class to which the selected individual belongs according to the prediction of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad10c84",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f2d1e",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[0]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a816bac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1eaf8",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef2a5d4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913db2b6",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[-1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ecb565",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation using heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23562c94",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The importance of the data present in the neural network is shown from explanation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7370351",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Items currently in use are retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"].reset_index(drop=True)\n",
    "\n",
    "## The data is prepared for the generation of heatmaps.\n",
    "column_Map = ds_item['Question'].tolist()\n",
    "content_Map = [False for x in range(1, df.shape[1])]\n",
    "\n",
    "## The next items to be deleted will be marked.\n",
    "for index in range(0, len(content_Map)):\n",
    "    \n",
    "    if iteration == 0:\n",
    "        for delete in list_contr:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "    else:\n",
    "        for delete in question_anomaly:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "\n",
    "## The dataframe is created with the prepared data.\n",
    "df_mask = pd.DataFrame([content_Map], columns = column_Map)\n",
    "df_mask_imp = pd.concat([df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "df_mask_all = pd.concat([df_mask, df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "\n",
    "df_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1597c2a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebec65b4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Identification of feature variables from the randomness of the answers as items of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f300b117",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Loading the data for explainability.\n",
    "explainer = ClassifierExplainer(mlp, X_test, y_test)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fada35",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c9427",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145ca866",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb56afd2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e8ad22",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77359501",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c0672",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db320a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_importance = pd.concat(map_class, axis=1)\n",
    "df_importance.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Reds\", cbar = False)\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Blues\",yticklabels = True, xticklabels = True ,mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d519a846",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d26d1d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e49af9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5bc56e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e8efed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127be32d",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c99add4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a791eb2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2747613",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e70eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d14cc8c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99845b1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6f8f5f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f5bb6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a28e95",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bafebe3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f143d78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d79877",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30dac9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b6f51",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d1c65",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa909dc5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242eba5e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddbf12b",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d5ea4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de9f844",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a557c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51aebcf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f69e1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee990a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c351240",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4ffdb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_shap = pd.concat(map_class, axis=1)\n",
    "df_shap.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb61b4b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4833c884",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a255294a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data preparation for explainability.\n",
    "lime_exp = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                  feature_names=train_cols, class_names=target_names,\n",
    "                                                  discretize_continuous=True)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990ee570",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by LIME about the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a544f3df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for LIME array data.\n",
    "exp_matrix = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for LIME.\n",
    "for x in X_test.to_numpy():\n",
    "    \n",
    "    ## Auxiliary temporary variables.\n",
    "    exp_list = [[] for _ in range(len(name_class))]\n",
    "    \n",
    "    ## Loading the data for explainability.\n",
    "    exp = lime_exp.explain_instance(x, mlp.predict_proba, num_features = df.shape[1] - 1, top_labels = len(name_class))\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "        temp = exp.as_map()[elements]\n",
    "        temp.sort(key=itemgetter(0))\n",
    "        \n",
    "        ## Saving data of the Low, Medium and High classes.\n",
    "        for tup in temp:\n",
    "            exp_list[elements].append(tup[1])\n",
    "            \n",
    "        exp_matrix[elements].append(exp_list[elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0457a1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2cc6a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d7a72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c9cebe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9e72c",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2681c7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538cf271",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc367bdd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d36d2be",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a59b24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c8ad0e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51c7b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbc2a88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a687a97b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cdd6fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e85ef7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb12be1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_lime = pd.concat(map_class, axis=1)\n",
    "df_lime.columns = name_class\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b985fa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cdd844",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It shows the main effect of each question compared to the probability that the model predicts in each class. This effect is shown for both responses. Since there are only 2 answers, the map is the same but with the colors reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406708b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names=train_cols, target_names= target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d61ae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by ALE about all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5916aa6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for ALE array data.\n",
    "ale_list = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for ALE.\n",
    "for array in proba_exp_lr.ale_values:\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "    \n",
    "        ## Saving data of all the classes.\n",
    "        ale_list[elements].append(array[0][elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be35902",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data processing for the explainability of ALE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a94c12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data processing of the Low, Medium and High classes.\n",
    "for elements in range(0, len(name_class)):\n",
    "    ale_df = pd.DataFrame([ale_list [elements]])\n",
    "    ale_df = pd.concat([ale_df.multiply(-1), ale_df])\n",
    "    ale_df.index = [name_class [elements] + \" - False\", name_class [elements] + \" - True\"]\n",
    "    ale_df.columns = column_Map\n",
    "    map_class.append(ale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3befc7e4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c048da",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce809039",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85773ff5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27905f15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb672c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0fe72c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3674f886",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc7fd44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068dabb9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee6018",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of absolute value to data.\n",
    "for index in range(0, len(map_class)):\n",
    "    map_class [index] = map_class [index][0:1].abs()\n",
    "\n",
    "## Union of the heatmaps of the Low, Medium and High class.\n",
    "ale_df = pd.concat(map_class)\n",
    "ale_df.index = name_class\n",
    "ale_df = ale_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c33a0a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb01c39",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask= df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71daede",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparing of Feature Variables Methods for Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c066bae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The global values of each of the methods used are taken, their maximums are obtained (the minimums are 0) and a percentage is calculated based on said maximum, which indicates how relevant the contribution is for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a215d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ec4c5e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87431507",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35002a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1836b52f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef378a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f498eef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a606922",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f138bff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65259bfb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d50809",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263d1dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb74c70",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0984b9ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c907f718",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9179c4bb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563935b7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28442acd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ade2aa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20495f35",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a4a441",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c02d549",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ecfce4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Safeguarding the items eliminated during this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c1bb3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Removal of anomalous items selected by selection_mode.\n",
    "for x in question_anomaly:\n",
    "\n",
    "    ## Status change of the deleted items in the respective auxiliary dataset.\n",
    "    ds.loc[x - 1,'Status'] = 'Delete'\n",
    "\n",
    "## Save the changed statuses in the dataset.\n",
    "ds.to_csv(path_dataset_qs, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2757c5b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iteration 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d9370",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first iteration of improvement of the model is carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf362f6c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing the data for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85764295",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data is prepared in order to be processed by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a387c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The iteration number is increased.\n",
    "iteration += 1\n",
    "\n",
    "## Loading data from the dataset.\n",
    "df = pd.read_csv(path_dataset)\n",
    "ds = pd.read_csv(path_dataset_qs)\n",
    "\n",
    "## Elimination of unrelated items from the dataset.\n",
    "if len(unrelated_questions) != 0:\n",
    "    df = df.drop(df.columns[unrelated_questions[0]:unrelated_questions[1]], axis=1)\n",
    "\n",
    "i = 0\n",
    "if iteration == 1:\n",
    "    ## Elimination of list of conflicting items declared in global variables.\n",
    "    for x in list_contr:\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "        ## Status change of the deleted question in the respective auxiliary dataset.\n",
    "        ds.loc[x - 1,'Status'] = 'Delete'\n",
    "    \n",
    "else:    \n",
    "    ## Elimination of the list of anomadic items defined in the improvement process.\n",
    "    ds_delete = ds[ds.Status == \"Delete\"].reset_index(drop=True)\n",
    "    for x in ds_delete['Question'].tolist():\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "\n",
    "## Grouping of the target according to the defined dictionary.\n",
    "if grouping_name != None and grouping_name != '':\n",
    "    df[grouping_name] = df[grouping_name].map(class_dic)\n",
    "\n",
    "## Assignment of local variables according to the data necessary for the neural network.\n",
    "train_cols = df.columns [0:-1]\n",
    "label = df.columns [-1]\n",
    "X = df [train_cols]\n",
    "y = df [label]\n",
    "\n",
    "## The prepared data of the dataset is printed.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b65ebed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Oversample application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b4d77",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An oversample process is applied to level the amount of existing data given by the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ae991",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The number of elements present in the grouped target is printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ae2108",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Oversample application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1a44f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of the oversample to the prepared data.\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d16d8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Printing of the data after the application of the oversample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5920b03d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The results obtained after applying the oversample are printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc336ba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparation of the parameters of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b98a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to define the parameters necessary for the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1684dec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e18300",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f7a97b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The alpha parameters and the initial learning rate are adjusted to obtain the best performance with the model\n",
    "using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276dda8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_normal\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = regul_param, \n",
    "             learning_rate = 'constant', learning_rate_init = 0.0001, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b1b675",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7472b0a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Alpha 10^{X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8202ef09",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The training is performed again keeping the same parameters except for the alpha value that changes to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffddfbd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_alpha\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = 1, \n",
    "             learning_rate = 'constant', learning_rate_init = regul_param, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1a80ae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37aa9de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Learning Rate 10^{-X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226c4067",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a92eb0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The parameters of the final model are modified according to the data obtained in the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e838f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The value of the alpha parameter, learning_rate_init and random_state are changed according\n",
    "## to the data in the global variables.\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = alpha,\n",
    "                            learning_rate = 'constant', learning_rate_init = learning_rate_init, max_iter = 100000,\n",
    "                            random_state = random_state_model)\n",
    "\n",
    "## We print the data of the final generated model.\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328bb85",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We safeguard the final generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8371e41f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(mlp,\"model_depression_i\" + str(iteration) + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a0524",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the confusion matrix of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f14c414",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We obtain the statistics of the final model to generate its confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1192e70f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The data for the generation of the confession matrix are defined.\n",
    "confusion_matrix = ConfusionMatrixDisplay.from_estimator(mlp, X_test, y_test, display_labels = target_names,\n",
    "                                                         cmap = plt.cm.Blues)\n",
    "confusion_matrix.ax_.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd7753",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get the detailed statistics of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788ceea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary detailed prediction is generated.\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "## The detailed statistics of the model are printed.\n",
    "print('Classification accuracy =',accuracy_score(y_test,y_pred) * 100,'%\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46e7dfd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data obtained is saved for later graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c51b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred) * 100\n",
    "clf_rep = precision_recall_fscore_support(y_test,y_pred)\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_delete = ds[ds.Status == \"Delete\"]\n",
    "ds_delete.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## All the metrics of the confusion matrix are obtained.\n",
    "metrics = [\",\".join(map(str, ds_delete['Question'].tolist())),\n",
    "           accuracy]\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    metrics.append(clf_rep[0][index])\n",
    "    metrics.append(clf_rep[1][index])\n",
    "    metrics.append(clf_rep[2][index])\n",
    "    metrics.append(clf_rep[3][index])\n",
    "\n",
    "## The names of the columns of the dataset are defined.\n",
    "columns = ['Question', 'Acurracy global']\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    columns.append('Precision_' + str(index))\n",
    "    columns.append('Recall_' + str(index))\n",
    "    columns.append('F1_score_' + str(index))\n",
    "    columns.append('Support_' + str(index))\n",
    "\n",
    "## A new row of the dataset is generated with all the data.\n",
    "data_metrics = pd.DataFrame([metrics], columns = columns)\n",
    "\n",
    "## The data is saved to the dataset.\n",
    "data_metrics.to_csv(path_dataset_qd, mode = 'a', header = False, index = False)\n",
    "\n",
    "## The data added to the dataset is printed.\n",
    "data_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d296f3d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Improvement process of the neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101c01d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The application of the explanation method by ALE allows to determine the behavior of the neural network and thereby improve it by discarding non-significant data for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757f9698",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope Analysis of ALE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32a782",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703747e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to obtain the graphs to obtain the slopes of the selected classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875ec090",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The question metrics dataset is loaded.\n",
    "dm = pd.DataFrame()\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"]\n",
    "ds_item.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## We get the slopes from the ALE data.\n",
    "for i in range(df.shape[1]-1):\n",
    "    structure_data = {'Question': ds_item.loc[i, \"Question\"]}\n",
    "    \n",
    "    for index in selection_class:\n",
    "        slope = proba_exp_lr.ale_values [i][1][index] - proba_exp_lr.ale_values [i][0][index]\n",
    "        structure_data['Slope ' + str(target_names[index])] = slope\n",
    "        structure_data['Threshold ' + str(target_names[index])] = 'NA'\n",
    "        structure_data['Anomaly ' + str(target_names[index])] = 'NA'\n",
    "        \n",
    "    dm = dm.append(structure_data, ignore_index=True)\n",
    "    \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c67044",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope analysis and threshold application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954a089f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The slope obtained is analyzed and those that are above or below the positive and negative threshold are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc34f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## The slopes are selected according to the values of the thresholds of the defined classes.\n",
    "        if dm.loc[i, \"Slope \" + str(target_names[index])] >= positive_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 1\n",
    "        elif dm.loc[i, \"Slope \" + str(target_names[index])] <= negative_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 0\n",
    "            \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f2d3cb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis and determination of anomalous items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ecc867",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The anomalous items present in the model are determined based on their slope and expected response from the expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe932d3a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The dataset of expected responses is loaded.\n",
    "da = pd.read_csv(path_dataset_qa)\n",
    "\n",
    "## Delete list of items deleted in this iteration.\n",
    "i = 0\n",
    "for x in ds_delete['Question']:\n",
    "    da.drop(da.index[x - (i + 1)], axis = 0, inplace = True)\n",
    "    i += 1\n",
    "\n",
    "## Indexes are restored for later use.\n",
    "da.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## The dataset of expected responses is printed.\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa49654",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to identify the anomadic items present in the model present in this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbdb7f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    \n",
    "    ## Local variable to indicate the index of the selected classes.\n",
    "    i_index = 0\n",
    "    \n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## Determine if it fails based on the expected response parameters of the defined classes.\n",
    "        if dm.loc[i, \"Threshold \"  + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][0]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][1]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][2]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \"  + str(target_names[index])] = expected_response_map[i_index][3]\n",
    "        \n",
    "        ## Increase of the index of the selected classes.\n",
    "        i_index += 1\n",
    "\n",
    "## The final grade data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1961d9d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Removing identified anomadic items from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae48858",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to eliminate the identified anomadic items so as not to use them in the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe9642",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variable for the elimination of the anomaly items.\n",
    "instructions = ''\n",
    "init = False\n",
    "question_anomaly = []\n",
    "\n",
    "if selection_mode == 1:\n",
    "    \n",
    "    ## Items that fail in the defined class are retrieved.\n",
    "    dm_delete = dm[dm['Anomaly ' + str(target_names[select_class_mode])] == 1]\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 2:\n",
    "    \n",
    "    ## Items that fail in classes defined with the or condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" or `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 3:\n",
    "    \n",
    "    ## Items that fail in classes defined with the and condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 4:\n",
    "    \n",
    "    ## Out-of-threshold items are retrieved in classes defined with the condition type and.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "\n",
    "## The selected blank items are printed according to the selection_mode.\n",
    "question_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c9c8b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model explainability process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7c1be",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data used for the test of the neural network model is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf5aecb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cdc45a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b1ec95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In analysis of the model through the results obtained by ALE, it is possible to identify the behavior of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8c1c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931558c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graphs of all the data present in the dataset used are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5daf4f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ale(proba_exp_lr, n_cols=2, features=list(range(df.shape[1]-1)),fig_kw={'figwidth': 10, 'figheight': 180});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b6659",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5abc36",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to explain the improved model using LIME for the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f56ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                   feature_names=train_cols, class_names=target_names, \n",
    "                                                   discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad73cd7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606291b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[0], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a059803a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954a2cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a066876d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316055b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[-1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce57280",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3566c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SHAP explanatory values are displayed according to the class to which the selected individual belongs according to the prediction of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d11da0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97464a48",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[0]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd858ea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b0236d",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e93cf3d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2248d0d8",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[-1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fcde4a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation using heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9118c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The importance of the data present in the neural network is shown from explanation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb699ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Items currently in use are retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"].reset_index(drop=True)\n",
    "\n",
    "## The data is prepared for the generation of heatmaps.\n",
    "column_Map = ds_item['Question'].tolist()\n",
    "content_Map = [False for x in range(1, df.shape[1])]\n",
    "\n",
    "## The next items to be deleted will be marked.\n",
    "for index in range(0, len(content_Map)):\n",
    "    \n",
    "    if iteration == 0:\n",
    "        for delete in list_contr:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "    else:\n",
    "        for delete in question_anomaly:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "\n",
    "## The dataframe is created with the prepared data.\n",
    "df_mask = pd.DataFrame([content_Map], columns = column_Map)\n",
    "df_mask_imp = pd.concat([df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "df_mask_all = pd.concat([df_mask, df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "\n",
    "df_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f719beee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab9b37c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Identification of feature variables from the randomness of the answers as items of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff5924b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Loading the data for explainability.\n",
    "explainer = ClassifierExplainer(mlp, X_test, y_test)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0b298b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c042a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e17f061",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed36131",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fa58d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00acfe83",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf58989",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4e358",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_importance = pd.concat(map_class, axis=1)\n",
    "df_importance.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Reds\", cbar = False)\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Blues\",yticklabels = True, xticklabels = True ,mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59030bc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd70613",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac00b071",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf4e85b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39f396c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3648ff9c",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee092df",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaacbaa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8e655b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6bbb01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41da9b23",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc81cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b01895",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af845f4f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a81aa47",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0262cd81",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce3076",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7441e5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ec6cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0101a660",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce708dc9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a8f1c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f822a6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a4c1a",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5756cdc4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b1bf8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65fd282",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88522e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536ae8e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7210d41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9311cb41",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d733869",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_shap = pd.concat(map_class, axis=1)\n",
    "df_shap.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ec6a34",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ffe36",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d2315",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data preparation for explainability.\n",
    "lime_exp = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                  feature_names=train_cols, class_names=target_names,\n",
    "                                                  discretize_continuous=True)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5530970",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by LIME about the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c8964",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for LIME array data.\n",
    "exp_matrix = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for LIME.\n",
    "for x in X_test.to_numpy():\n",
    "    \n",
    "    ## Auxiliary temporary variables.\n",
    "    exp_list = [[] for _ in range(len(name_class))]\n",
    "    \n",
    "    ## Loading the data for explainability.\n",
    "    exp = lime_exp.explain_instance(x, mlp.predict_proba, num_features = df.shape[1] - 1, top_labels = len(name_class))\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "        temp = exp.as_map()[elements]\n",
    "        temp.sort(key=itemgetter(0))\n",
    "        \n",
    "        ## Saving data of the Low, Medium and High classes.\n",
    "        for tup in temp:\n",
    "            exp_list[elements].append(tup[1])\n",
    "            \n",
    "        exp_matrix[elements].append(exp_list[elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a003fa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04982d5c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a0d462",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d8ec2b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42328bf1",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793db38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0494ed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a5f94",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8e87ca",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f374934f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c8705c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b1817",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9fb182",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c65ee5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb62d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e4e3a0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa13aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_lime = pd.concat(map_class, axis=1)\n",
    "df_lime.columns = name_class\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee22d25",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c117034",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It shows the main effect of each question compared to the probability that the model predicts in each class. This effect is shown for both responses. Since there are only 2 answers, the map is the same but with the colors reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96830055",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names=train_cols, target_names= target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b32296",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by ALE about all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad07c322",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for ALE array data.\n",
    "ale_list = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for ALE.\n",
    "for array in proba_exp_lr.ale_values:\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "    \n",
    "        ## Saving data of all the classes.\n",
    "        ale_list[elements].append(array[0][elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5380f9fa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data processing for the explainability of ALE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acaf993",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data processing of the Low, Medium and High classes.\n",
    "for elements in range(0, len(name_class)):\n",
    "    ale_df = pd.DataFrame([ale_list [elements]])\n",
    "    ale_df = pd.concat([ale_df.multiply(-1), ale_df])\n",
    "    ale_df.index = [name_class [elements] + \" - False\", name_class [elements] + \" - True\"]\n",
    "    ale_df.columns = column_Map\n",
    "    map_class.append(ale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e72ae9f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f2e099",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a7f323",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf43ab6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db901cc8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46237e69",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008d240",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2b109",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3458025f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a137cd2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca191a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of absolute value to data.\n",
    "for index in range(0, len(map_class)):\n",
    "    map_class [index] = map_class [index][0:1].abs()\n",
    "\n",
    "## Union of the heatmaps of the Low, Medium and High class.\n",
    "ale_df = pd.concat(map_class)\n",
    "ale_df.index = name_class\n",
    "ale_df = ale_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032ad60",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9cc108",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask= df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2ef64",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparing of Feature Variables Methods for Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3612958f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The global values of each of the methods used are taken, their maximums are obtained (the minimums are 0) and a percentage is calculated based on said maximum, which indicates how relevant the contribution is for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d35198",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f92ff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c8d157",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2df738",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded9657",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80c7ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d81830",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead2a8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603db76d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e476503",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed48640b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89986e2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97873412",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5a3c86",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb89f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701b3ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386b785",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcebce5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae891ea4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0959b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87044b03",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d742a923",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d84ed3a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Safeguarding the items eliminated during this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9059951",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Removal of anomalous items selected by selection_mode.\n",
    "for x in question_anomaly:\n",
    "\n",
    "    ## Status change of the deleted items in the respective auxiliary dataset.\n",
    "    ds.loc[x - 1,'Status'] = 'Delete'\n",
    "\n",
    "## Save the changed statuses in the dataset.\n",
    "ds.to_csv(path_dataset_qs, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde9aa7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iteration 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dee01e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first iteration of improvement of the model is carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8644b5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing the data for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20714e77",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data is prepared in order to be processed by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9f01b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The iteration number is increased.\n",
    "iteration += 1\n",
    "\n",
    "## Loading data from the dataset.\n",
    "df = pd.read_csv(path_dataset)\n",
    "ds = pd.read_csv(path_dataset_qs)\n",
    "\n",
    "## Elimination of unrelated items from the dataset.\n",
    "if len(unrelated_questions) != 0:\n",
    "    df = df.drop(df.columns[unrelated_questions[0]:unrelated_questions[1]], axis=1)\n",
    "\n",
    "i = 0\n",
    "if iteration == 1:\n",
    "    ## Elimination of list of conflicting items declared in global variables.\n",
    "    for x in list_contr:\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "        ## Status change of the deleted question in the respective auxiliary dataset.\n",
    "        ds.loc[x - 1,'Status'] = 'Delete'\n",
    "    \n",
    "else:    \n",
    "    ## Elimination of the list of anomadic items defined in the improvement process.\n",
    "    ds_delete = ds[ds.Status == \"Delete\"].reset_index(drop=True)\n",
    "    for x in ds_delete['Question'].tolist():\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "\n",
    "## Grouping of the target according to the defined dictionary.\n",
    "if grouping_name != None and grouping_name != '':\n",
    "    df[grouping_name] = df[grouping_name].map(class_dic)\n",
    "\n",
    "## Assignment of local variables according to the data necessary for the neural network.\n",
    "train_cols = df.columns [0:-1]\n",
    "label = df.columns [-1]\n",
    "X = df [train_cols]\n",
    "y = df [label]\n",
    "\n",
    "## The prepared data of the dataset is printed.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f90c9cc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Oversample application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2486830",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An oversample process is applied to level the amount of existing data given by the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b11d1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The number of elements present in the grouped target is printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f483ea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Oversample application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6fe73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of the oversample to the prepared data.\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d080f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Printing of the data after the application of the oversample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ce611",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The results obtained after applying the oversample are printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26634c62",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparation of the parameters of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c36f07f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to define the parameters necessary for the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916e79f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd3d714",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a78e4e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The alpha parameters and the initial learning rate are adjusted to obtain the best performance with the model\n",
    "using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf99961",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_normal\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = regul_param, \n",
    "             learning_rate = 'constant', learning_rate_init = 0.0001, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a328a67f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f971c7e3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Alpha 10^{X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d532cd40",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The training is performed again keeping the same parameters except for the alpha value that changes to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a5a3dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_alpha\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = 1, \n",
    "             learning_rate = 'constant', learning_rate_init = regul_param, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49341e8b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c8e6dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Learning Rate 10^{-X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78655704",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a6d6f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The parameters of the final model are modified according to the data obtained in the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7358a201",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The value of the alpha parameter, learning_rate_init and random_state are changed according\n",
    "## to the data in the global variables.\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = alpha,\n",
    "                            learning_rate = 'constant', learning_rate_init = learning_rate_init, max_iter = 100000,\n",
    "                            random_state = random_state_model)\n",
    "\n",
    "## We print the data of the final generated model.\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b52b72",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We safeguard the final generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252b5f2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(mlp,\"model_depression_i\" + str(iteration) + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f9bfd6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the confusion matrix of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c7f02",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We obtain the statistics of the final model to generate its confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7908bc1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The data for the generation of the confession matrix are defined.\n",
    "confusion_matrix = ConfusionMatrixDisplay.from_estimator(mlp, X_test, y_test, display_labels = target_names,\n",
    "                                                         cmap = plt.cm.Blues)\n",
    "confusion_matrix.ax_.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b036986",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get the detailed statistics of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17857f79",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary detailed prediction is generated.\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "## The detailed statistics of the model are printed.\n",
    "print('Classification accuracy =',accuracy_score(y_test,y_pred) * 100,'%\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2681a1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data obtained is saved for later graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca460f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred) * 100\n",
    "clf_rep = precision_recall_fscore_support(y_test,y_pred)\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_delete = ds[ds.Status == \"Delete\"]\n",
    "ds_delete.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## All the metrics of the confusion matrix are obtained.\n",
    "metrics = [\",\".join(map(str, ds_delete['Question'].tolist())),\n",
    "           accuracy]\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    metrics.append(clf_rep[0][index])\n",
    "    metrics.append(clf_rep[1][index])\n",
    "    metrics.append(clf_rep[2][index])\n",
    "    metrics.append(clf_rep[3][index])\n",
    "\n",
    "## The names of the columns of the dataset are defined.\n",
    "columns = ['Question', 'Acurracy global']\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    columns.append('Precision_' + str(index))\n",
    "    columns.append('Recall_' + str(index))\n",
    "    columns.append('F1_score_' + str(index))\n",
    "    columns.append('Support_' + str(index))\n",
    "\n",
    "## A new row of the dataset is generated with all the data.\n",
    "data_metrics = pd.DataFrame([metrics], columns = columns)\n",
    "\n",
    "## The data is saved to the dataset.\n",
    "data_metrics.to_csv(path_dataset_qd, mode = 'a', header = False, index = False)\n",
    "\n",
    "## The data added to the dataset is printed.\n",
    "data_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017270b8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Improvement process of the neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aff952",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The application of the explanation method by ALE allows to determine the behavior of the neural network and thereby improve it by discarding non-significant data for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62648c5c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope Analysis of ALE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893fe79f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a114fd4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to obtain the graphs to obtain the slopes of the selected classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6431a5e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The question metrics dataset is loaded.\n",
    "dm = pd.DataFrame()\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"]\n",
    "ds_item.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## We get the slopes from the ALE data.\n",
    "for i in range(df.shape[1]-1):\n",
    "    structure_data = {'Question': ds_item.loc[i, \"Question\"]}\n",
    "    \n",
    "    for index in selection_class:\n",
    "        slope = proba_exp_lr.ale_values [i][1][index] - proba_exp_lr.ale_values [i][0][index]\n",
    "        structure_data['Slope ' + str(target_names[index])] = slope\n",
    "        structure_data['Threshold ' + str(target_names[index])] = 'NA'\n",
    "        structure_data['Anomaly ' + str(target_names[index])] = 'NA'\n",
    "        \n",
    "    dm = dm.append(structure_data, ignore_index=True)\n",
    "    \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb73dbd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope analysis and threshold application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd994c6a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The slope obtained is analyzed and those that are above or below the positive and negative threshold are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d0aba2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## The slopes are selected according to the values of the thresholds of the defined classes.\n",
    "        if dm.loc[i, \"Slope \" + str(target_names[index])] >= positive_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 1\n",
    "        elif dm.loc[i, \"Slope \" + str(target_names[index])] <= negative_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 0\n",
    "            \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd884747",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis and determination of anomalous items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb2d21",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The anomalous items present in the model are determined based on their slope and expected response from the expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb368169",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The dataset of expected responses is loaded.\n",
    "da = pd.read_csv(path_dataset_qa)\n",
    "\n",
    "## Delete list of items deleted in this iteration.\n",
    "i = 0\n",
    "for x in ds_delete['Question']:\n",
    "    da.drop(da.index[x - (i + 1)], axis = 0, inplace = True)\n",
    "    i += 1\n",
    "\n",
    "## Indexes are restored for later use.\n",
    "da.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## The dataset of expected responses is printed.\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe0a1d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to identify the anomadic items present in the model present in this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b637e7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    \n",
    "    ## Local variable to indicate the index of the selected classes.\n",
    "    i_index = 0\n",
    "    \n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## Determine if it fails based on the expected response parameters of the defined classes.\n",
    "        if dm.loc[i, \"Threshold \"  + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][0]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][1]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][2]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \"  + str(target_names[index])] = expected_response_map[i_index][3]\n",
    "        \n",
    "        ## Increase of the index of the selected classes.\n",
    "        i_index += 1\n",
    "\n",
    "## The final grade data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07becc0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Removing identified anomadic items from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb6e35",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to eliminate the identified anomadic items so as not to use them in the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa507a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variable for the elimination of the anomaly items.\n",
    "instructions = ''\n",
    "init = False\n",
    "question_anomaly = []\n",
    "\n",
    "if selection_mode == 1:\n",
    "    \n",
    "    ## Items that fail in the defined class are retrieved.\n",
    "    dm_delete = dm[dm['Anomaly ' + str(target_names[select_class_mode])] == 1]\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 2:\n",
    "    \n",
    "    ## Items that fail in classes defined with the or condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" or `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 3:\n",
    "    \n",
    "    ## Items that fail in classes defined with the and condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 4:\n",
    "    \n",
    "    ## Out-of-threshold items are retrieved in classes defined with the condition type and.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "\n",
    "## The selected blank items are printed according to the selection_mode.\n",
    "question_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a64af",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model explainability process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8eee96",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data used for the test of the neural network model is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62540557",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ded9e05",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474e0eb5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In analysis of the model through the results obtained by ALE, it is possible to identify the behavior of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262c5d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427c134",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graphs of all the data present in the dataset used are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1bb630",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ale(proba_exp_lr, n_cols=2, features=list(range(df.shape[1]-1)),fig_kw={'figwidth': 10, 'figheight': 180});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330aa6f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb2984",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to explain the improved model using LIME for the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7897ba5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                   feature_names=train_cols, class_names=target_names, \n",
    "                                                   discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ace2205",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d13dfbb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[0], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9c520",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae88823",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff523651",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c442cb6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[-1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce9a4e1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0993fd47",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SHAP explanatory values are displayed according to the class to which the selected individual belongs according to the prediction of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78b684",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c62ee9",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[0]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de31978",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48cbe04",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c887d6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564b1cc",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[-1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dff470e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation using heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fbdba0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The importance of the data present in the neural network is shown from explanation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45191579",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Items currently in use are retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"].reset_index(drop=True)\n",
    "\n",
    "## The data is prepared for the generation of heatmaps.\n",
    "column_Map = ds_item['Question'].tolist()\n",
    "content_Map = [False for x in range(1, df.shape[1])]\n",
    "\n",
    "## The next items to be deleted will be marked.\n",
    "for index in range(0, len(content_Map)):\n",
    "    \n",
    "    if iteration == 0:\n",
    "        for delete in list_contr:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "    else:\n",
    "        for delete in question_anomaly:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "\n",
    "## The dataframe is created with the prepared data.\n",
    "df_mask = pd.DataFrame([content_Map], columns = column_Map)\n",
    "df_mask_imp = pd.concat([df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "df_mask_all = pd.concat([df_mask, df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "\n",
    "df_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1890897",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a880816",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Identification of feature variables from the randomness of the answers as items of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e77ef56",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Loading the data for explainability.\n",
    "explainer = ClassifierExplainer(mlp, X_test, y_test)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c430bf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1df5c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc1543",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ade1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdd177d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813881e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8832fb19",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9a5d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_importance = pd.concat(map_class, axis=1)\n",
    "df_importance.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Reds\", cbar = False)\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Blues\",yticklabels = True, xticklabels = True ,mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca9652",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2550650",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b00b95",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8296a667",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb755bcc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b99953",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf03d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8699cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591b810",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea55603",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a976139e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ea330e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb2d335",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a396aea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211151b",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193cd5a6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b2fe39",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e2e947",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1ac5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f274d81d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16cfae9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a969c22f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60018a55",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4661ed59",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd5f0c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6072a13",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9554ff78",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b08eb9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73017f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb2bb8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aad70f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802fe37d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_shap = pd.concat(map_class, axis=1)\n",
    "df_shap.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed4be4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9021c24",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9c0a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data preparation for explainability.\n",
    "lime_exp = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                  feature_names=train_cols, class_names=target_names,\n",
    "                                                  discretize_continuous=True)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3801281",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by LIME about the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8522d52",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for LIME array data.\n",
    "exp_matrix = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for LIME.\n",
    "for x in X_test.to_numpy():\n",
    "    \n",
    "    ## Auxiliary temporary variables.\n",
    "    exp_list = [[] for _ in range(len(name_class))]\n",
    "    \n",
    "    ## Loading the data for explainability.\n",
    "    exp = lime_exp.explain_instance(x, mlp.predict_proba, num_features = df.shape[1] - 1, top_labels = len(name_class))\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "        temp = exp.as_map()[elements]\n",
    "        temp.sort(key=itemgetter(0))\n",
    "        \n",
    "        ## Saving data of the Low, Medium and High classes.\n",
    "        for tup in temp:\n",
    "            exp_list[elements].append(tup[1])\n",
    "            \n",
    "        exp_matrix[elements].append(exp_list[elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a2c231",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e7332",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07472273",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb7806",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4502b4",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde150ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2397ae5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bac998",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd00d96",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce4ad53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448a4d65",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a759b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be97b68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748ed1d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899fd93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57fc16b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c40c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_lime = pd.concat(map_class, axis=1)\n",
    "df_lime.columns = name_class\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee39ea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c5c26",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It shows the main effect of each question compared to the probability that the model predicts in each class. This effect is shown for both responses. Since there are only 2 answers, the map is the same but with the colors reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba8b342",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names=train_cols, target_names= target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bceadf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by ALE about all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6734be8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for ALE array data.\n",
    "ale_list = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for ALE.\n",
    "for array in proba_exp_lr.ale_values:\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "    \n",
    "        ## Saving data of all the classes.\n",
    "        ale_list[elements].append(array[0][elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea6a861",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data processing for the explainability of ALE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068df7a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data processing of the Low, Medium and High classes.\n",
    "for elements in range(0, len(name_class)):\n",
    "    ale_df = pd.DataFrame([ale_list [elements]])\n",
    "    ale_df = pd.concat([ale_df.multiply(-1), ale_df])\n",
    "    ale_df.index = [name_class [elements] + \" - False\", name_class [elements] + \" - True\"]\n",
    "    ale_df.columns = column_Map\n",
    "    map_class.append(ale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf769d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc59627",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b80e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e837a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c865e0a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0725f1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6e6b98",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da43aff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2301e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5805377d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a81cac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of absolute value to data.\n",
    "for index in range(0, len(map_class)):\n",
    "    map_class [index] = map_class [index][0:1].abs()\n",
    "\n",
    "## Union of the heatmaps of the Low, Medium and High class.\n",
    "ale_df = pd.concat(map_class)\n",
    "ale_df.index = name_class\n",
    "ale_df = ale_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b9340",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d0be23",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask= df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cffd2a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparing of Feature Variables Methods for Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75809f5d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The global values of each of the methods used are taken, their maximums are obtained (the minimums are 0) and a percentage is calculated based on said maximum, which indicates how relevant the contribution is for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a2fb36",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee4227a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d0572",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd0946",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4110fe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f77c388",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af22d43",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53a74e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8299e7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a15f0e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37197403",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf578b40",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b071cd9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9870c4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba6bd5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374eba73",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf744c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d4073",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef29f806",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e742779",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a3c11",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9cfad3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32765871",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Safeguarding the items eliminated during this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86642d25",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Removal of anomalous items selected by selection_mode.\n",
    "for x in question_anomaly:\n",
    "\n",
    "    ## Status change of the deleted items in the respective auxiliary dataset.\n",
    "    ds.loc[x - 1,'Status'] = 'Delete'\n",
    "\n",
    "## Save the changed statuses in the dataset.\n",
    "ds.to_csv(path_dataset_qs, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aa0c4d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iteration 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd6a260",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first iteration of improvement of the model is carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9c39bb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing the data for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12956e3e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data is prepared in order to be processed by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e910eae2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The iteration number is increased.\n",
    "iteration += 1\n",
    "\n",
    "## Loading data from the dataset.\n",
    "df = pd.read_csv(path_dataset)\n",
    "ds = pd.read_csv(path_dataset_qs)\n",
    "\n",
    "## Elimination of unrelated items from the dataset.\n",
    "if len(unrelated_questions) != 0:\n",
    "    df = df.drop(df.columns[unrelated_questions[0]:unrelated_questions[1]], axis=1)\n",
    "\n",
    "i = 0\n",
    "if iteration == 1:\n",
    "    ## Elimination of list of conflicting items declared in global variables.\n",
    "    for x in list_contr:\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "        ## Status change of the deleted question in the respective auxiliary dataset.\n",
    "        ds.loc[x - 1,'Status'] = 'Delete'\n",
    "    \n",
    "else:    \n",
    "    ## Elimination of the list of anomadic items defined in the improvement process.\n",
    "    ds_delete = ds[ds.Status == \"Delete\"].reset_index(drop=True)\n",
    "    for x in ds_delete['Question'].tolist():\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "\n",
    "## Grouping of the target according to the defined dictionary.\n",
    "if grouping_name != None and grouping_name != '':\n",
    "    df[grouping_name] = df[grouping_name].map(class_dic)\n",
    "\n",
    "## Assignment of local variables according to the data necessary for the neural network.\n",
    "train_cols = df.columns [0:-1]\n",
    "label = df.columns [-1]\n",
    "X = df [train_cols]\n",
    "y = df [label]\n",
    "\n",
    "## The prepared data of the dataset is printed.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda2a32",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Oversample application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab89ad3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An oversample process is applied to level the amount of existing data given by the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05963a00",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The number of elements present in the grouped target is printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba2fbc3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Oversample application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf94c3d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of the oversample to the prepared data.\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdabea2a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Printing of the data after the application of the oversample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d65b71",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The results obtained after applying the oversample are printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad539d5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparation of the parameters of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa460c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to define the parameters necessary for the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a10c70e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877385e7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72134548",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The alpha parameters and the initial learning rate are adjusted to obtain the best performance with the model\n",
    "using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c838a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_normal\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = regul_param, \n",
    "             learning_rate = 'constant', learning_rate_init = 0.0001, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed2baa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c304b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Alpha 10^{X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0236fc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The training is performed again keeping the same parameters except for the alpha value that changes to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c995bb7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_alpha\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = 1, \n",
    "             learning_rate = 'constant', learning_rate_init = regul_param, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b06640",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c6d9f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Learning Rate 10^{-X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb04fd8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe64cd8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The parameters of the final model are modified according to the data obtained in the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa3eda",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The value of the alpha parameter, learning_rate_init and random_state are changed according\n",
    "## to the data in the global variables.\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = alpha,\n",
    "                            learning_rate = 'constant', learning_rate_init = learning_rate_init, max_iter = 100000,\n",
    "                            random_state = random_state_model)\n",
    "\n",
    "## We print the data of the final generated model.\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c276b5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We safeguard the final generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee20d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(mlp,\"model_depression_i\" + str(iteration) + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0462383e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the confusion matrix of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f364f2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We obtain the statistics of the final model to generate its confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca8a15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The data for the generation of the confession matrix are defined.\n",
    "confusion_matrix = ConfusionMatrixDisplay.from_estimator(mlp, X_test, y_test, display_labels = target_names,\n",
    "                                                         cmap = plt.cm.Blues)\n",
    "confusion_matrix.ax_.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd7bebd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get the detailed statistics of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b883dfdd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary detailed prediction is generated.\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "## The detailed statistics of the model are printed.\n",
    "print('Classification accuracy =',accuracy_score(y_test,y_pred) * 100,'%\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d42ad88",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data obtained is saved for later graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be056ad5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred) * 100\n",
    "clf_rep = precision_recall_fscore_support(y_test,y_pred)\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_delete = ds[ds.Status == \"Delete\"]\n",
    "ds_delete.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## All the metrics of the confusion matrix are obtained.\n",
    "metrics = [\",\".join(map(str, ds_delete['Question'].tolist())),\n",
    "           accuracy]\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    metrics.append(clf_rep[0][index])\n",
    "    metrics.append(clf_rep[1][index])\n",
    "    metrics.append(clf_rep[2][index])\n",
    "    metrics.append(clf_rep[3][index])\n",
    "\n",
    "## The names of the columns of the dataset are defined.\n",
    "columns = ['Question', 'Acurracy global']\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    columns.append('Precision_' + str(index))\n",
    "    columns.append('Recall_' + str(index))\n",
    "    columns.append('F1_score_' + str(index))\n",
    "    columns.append('Support_' + str(index))\n",
    "\n",
    "## A new row of the dataset is generated with all the data.\n",
    "data_metrics = pd.DataFrame([metrics], columns = columns)\n",
    "\n",
    "## The data is saved to the dataset.\n",
    "data_metrics.to_csv(path_dataset_qd, mode = 'a', header = False, index = False)\n",
    "\n",
    "## The data added to the dataset is printed.\n",
    "data_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba96a1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Improvement process of the neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73993864",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The application of the explanation method by ALE allows to determine the behavior of the neural network and thereby improve it by discarding non-significant data for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a75d8a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope Analysis of ALE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e4abaf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead5fc2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to obtain the graphs to obtain the slopes of the selected classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fbb139",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The question metrics dataset is loaded.\n",
    "dm = pd.DataFrame()\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"]\n",
    "ds_item.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## We get the slopes from the ALE data.\n",
    "for i in range(df.shape[1]-1):\n",
    "    structure_data = {'Question': ds_item.loc[i, \"Question\"]}\n",
    "    \n",
    "    for index in selection_class:\n",
    "        slope = proba_exp_lr.ale_values [i][1][index] - proba_exp_lr.ale_values [i][0][index]\n",
    "        structure_data['Slope ' + str(target_names[index])] = slope\n",
    "        structure_data['Threshold ' + str(target_names[index])] = 'NA'\n",
    "        structure_data['Anomaly ' + str(target_names[index])] = 'NA'\n",
    "        \n",
    "    dm = dm.append(structure_data, ignore_index=True)\n",
    "    \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d4e73",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope analysis and threshold application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e179d433",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The slope obtained is analyzed and those that are above or below the positive and negative threshold are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021292f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## The slopes are selected according to the values of the thresholds of the defined classes.\n",
    "        if dm.loc[i, \"Slope \" + str(target_names[index])] >= positive_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 1\n",
    "        elif dm.loc[i, \"Slope \" + str(target_names[index])] <= negative_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 0\n",
    "            \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc01d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis and determination of anomalous items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d083cb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The anomalous items present in the model are determined based on their slope and expected response from the expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ddbe6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The dataset of expected responses is loaded.\n",
    "da = pd.read_csv(path_dataset_qa)\n",
    "\n",
    "## Delete list of items deleted in this iteration.\n",
    "i = 0\n",
    "for x in ds_delete['Question']:\n",
    "    da.drop(da.index[x - (i + 1)], axis = 0, inplace = True)\n",
    "    i += 1\n",
    "\n",
    "## Indexes are restored for later use.\n",
    "da.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## The dataset of expected responses is printed.\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c14e40",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to identify the anomadic items present in the model present in this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cfb396",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    \n",
    "    ## Local variable to indicate the index of the selected classes.\n",
    "    i_index = 0\n",
    "    \n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## Determine if it fails based on the expected response parameters of the defined classes.\n",
    "        if dm.loc[i, \"Threshold \"  + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][0]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][1]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][2]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \"  + str(target_names[index])] = expected_response_map[i_index][3]\n",
    "        \n",
    "        ## Increase of the index of the selected classes.\n",
    "        i_index += 1\n",
    "\n",
    "## The final grade data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707cdc5d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Removing identified anomadic items from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035819f1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to eliminate the identified anomadic items so as not to use them in the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa8304d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variable for the elimination of the anomaly items.\n",
    "instructions = ''\n",
    "init = False\n",
    "question_anomaly = []\n",
    "\n",
    "if selection_mode == 1:\n",
    "    \n",
    "    ## Items that fail in the defined class are retrieved.\n",
    "    dm_delete = dm[dm['Anomaly ' + str(target_names[select_class_mode])] == 1]\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 2:\n",
    "    \n",
    "    ## Items that fail in classes defined with the or condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" or `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 3:\n",
    "    \n",
    "    ## Items that fail in classes defined with the and condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 4:\n",
    "    \n",
    "    ## Out-of-threshold items are retrieved in classes defined with the condition type and.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "\n",
    "## The selected blank items are printed according to the selection_mode.\n",
    "question_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0554dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model explainability process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144de388",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data used for the test of the neural network model is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80f159",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cdb43d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b475ada2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In analysis of the model through the results obtained by ALE, it is possible to identify the behavior of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e76d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d139b9ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graphs of all the data present in the dataset used are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8f79d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ale(proba_exp_lr, n_cols=2, features=list(range(df.shape[1]-1)),fig_kw={'figwidth': 10, 'figheight': 180});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879c9aa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c626075",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to explain the improved model using LIME for the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d1836c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                   feature_names=train_cols, class_names=target_names, \n",
    "                                                   discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4997b1b4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765625e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[0], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9df4e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc5cdf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440ed467",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de9fc1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[-1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbbd3fb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba4cff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SHAP explanatory values are displayed according to the class to which the selected individual belongs according to the prediction of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b23be3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200a75a",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[0]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0c2ac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf6e51",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa38b2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3485d36",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[-1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f84704",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation using heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8832190b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The importance of the data present in the neural network is shown from explanation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2952d181",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Items currently in use are retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"].reset_index(drop=True)\n",
    "\n",
    "## The data is prepared for the generation of heatmaps.\n",
    "column_Map = ds_item['Question'].tolist()\n",
    "content_Map = [False for x in range(1, df.shape[1])]\n",
    "\n",
    "## The next items to be deleted will be marked.\n",
    "for index in range(0, len(content_Map)):\n",
    "    \n",
    "    if iteration == 0:\n",
    "        for delete in list_contr:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "    else:\n",
    "        for delete in question_anomaly:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "\n",
    "## The dataframe is created with the prepared data.\n",
    "df_mask = pd.DataFrame([content_Map], columns = column_Map)\n",
    "df_mask_imp = pd.concat([df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "df_mask_all = pd.concat([df_mask, df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "\n",
    "df_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7871195c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63786093",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Identification of feature variables from the randomness of the answers as items of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c27b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Loading the data for explainability.\n",
    "explainer = ClassifierExplainer(mlp, X_test, y_test)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524507e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10dbb22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658b74d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c04fac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eed748",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a329da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfc55fa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98b9be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_importance = pd.concat(map_class, axis=1)\n",
    "df_importance.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Reds\", cbar = False)\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Blues\",yticklabels = True, xticklabels = True ,mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc51e02",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37a9279",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f4cae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67090564",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aaf407",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a80cb2",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b6537",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd09d6c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf815d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b97093",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6397eff0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd7a62b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce01a88",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4c6674",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213f529d",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd86f90",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c95b39",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689db438",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079df00",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a36cfc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30859cca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb98f784",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b980a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5318041",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af74b9f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88008af9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78ae406",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a11dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7d379c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc0f5e3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce3da5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b1651",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_shap = pd.concat(map_class, axis=1)\n",
    "df_shap.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6839ed5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d5778",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d71d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data preparation for explainability.\n",
    "lime_exp = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                  feature_names=train_cols, class_names=target_names,\n",
    "                                                  discretize_continuous=True)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7882023d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by LIME about the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f757611",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for LIME array data.\n",
    "exp_matrix = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for LIME.\n",
    "for x in X_test.to_numpy():\n",
    "    \n",
    "    ## Auxiliary temporary variables.\n",
    "    exp_list = [[] for _ in range(len(name_class))]\n",
    "    \n",
    "    ## Loading the data for explainability.\n",
    "    exp = lime_exp.explain_instance(x, mlp.predict_proba, num_features = df.shape[1] - 1, top_labels = len(name_class))\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "        temp = exp.as_map()[elements]\n",
    "        temp.sort(key=itemgetter(0))\n",
    "        \n",
    "        ## Saving data of the Low, Medium and High classes.\n",
    "        for tup in temp:\n",
    "            exp_list[elements].append(tup[1])\n",
    "            \n",
    "        exp_matrix[elements].append(exp_list[elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655cc3a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e9ec4f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e044d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fcb1d4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809999b6",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc058d63",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366555f2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc95bc00",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1f0224",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b1b5e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8930d258",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf6c26e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c12c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf7ecf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e82ac3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a846b28",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71029e4e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_lime = pd.concat(map_class, axis=1)\n",
    "df_lime.columns = name_class\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e129dd8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abddfd2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It shows the main effect of each question compared to the probability that the model predicts in each class. This effect is shown for both responses. Since there are only 2 answers, the map is the same but with the colors reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd15d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names=train_cols, target_names= target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5204a25a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by ALE about all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056272a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for ALE array data.\n",
    "ale_list = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for ALE.\n",
    "for array in proba_exp_lr.ale_values:\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "    \n",
    "        ## Saving data of all the classes.\n",
    "        ale_list[elements].append(array[0][elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a6a750",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data processing for the explainability of ALE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca36c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data processing of the Low, Medium and High classes.\n",
    "for elements in range(0, len(name_class)):\n",
    "    ale_df = pd.DataFrame([ale_list [elements]])\n",
    "    ale_df = pd.concat([ale_df.multiply(-1), ale_df])\n",
    "    ale_df.index = [name_class [elements] + \" - False\", name_class [elements] + \" - True\"]\n",
    "    ale_df.columns = column_Map\n",
    "    map_class.append(ale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c41094b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be2bb5e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be27422c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5454ff56",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caff094d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe9f17",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642878d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb0b01c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d0104f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024a1584",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f6329",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of absolute value to data.\n",
    "for index in range(0, len(map_class)):\n",
    "    map_class [index] = map_class [index][0:1].abs()\n",
    "\n",
    "## Union of the heatmaps of the Low, Medium and High class.\n",
    "ale_df = pd.concat(map_class)\n",
    "ale_df.index = name_class\n",
    "ale_df = ale_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5154413d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318caf4a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask= df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd0fb5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparing of Feature Variables Methods for Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291b288",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The global values of each of the methods used are taken, their maximums are obtained (the minimums are 0) and a percentage is calculated based on said maximum, which indicates how relevant the contribution is for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749200b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa825f45",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b418bcd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6a90a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3842b96",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87145d3f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd97f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f49ba38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf516ba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f893bead",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0482e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd0ee05",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac38c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ed3097",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550f04d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f4e6df",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1477900",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4adf5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5bacd1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d425f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bef493",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a883a6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee6dd2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Safeguarding the items eliminated during this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9dda9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Removal of anomalous items selected by selection_mode.\n",
    "for x in question_anomaly:\n",
    "\n",
    "    ## Status change of the deleted items in the respective auxiliary dataset.\n",
    "    ds.loc[x - 1,'Status'] = 'Delete'\n",
    "\n",
    "## Save the changed statuses in the dataset.\n",
    "ds.to_csv(path_dataset_qs, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a6a6d5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iteration 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b94b97",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first iteration of improvement of the model is carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea11eb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing the data for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f1c4b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data is prepared in order to be processed by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b1ce8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The iteration number is increased.\n",
    "iteration += 1\n",
    "\n",
    "## Loading data from the dataset.\n",
    "df = pd.read_csv(path_dataset)\n",
    "ds = pd.read_csv(path_dataset_qs)\n",
    "\n",
    "## Elimination of unrelated items from the dataset.\n",
    "if len(unrelated_questions) != 0:\n",
    "    df = df.drop(df.columns[unrelated_questions[0]:unrelated_questions[1]], axis=1)\n",
    "\n",
    "i = 0\n",
    "if iteration == 1:\n",
    "    ## Elimination of list of conflicting items declared in global variables.\n",
    "    for x in list_contr:\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "        ## Status change of the deleted question in the respective auxiliary dataset.\n",
    "        ds.loc[x - 1,'Status'] = 'Delete'\n",
    "    \n",
    "else:    \n",
    "    ## Elimination of the list of anomadic items defined in the improvement process.\n",
    "    ds_delete = ds[ds.Status == \"Delete\"].reset_index(drop=True)\n",
    "    for x in ds_delete['Question'].tolist():\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "\n",
    "## Grouping of the target according to the defined dictionary.\n",
    "if grouping_name != None and grouping_name != '':\n",
    "    df[grouping_name] = df[grouping_name].map(class_dic)\n",
    "\n",
    "## Assignment of local variables according to the data necessary for the neural network.\n",
    "train_cols = df.columns [0:-1]\n",
    "label = df.columns [-1]\n",
    "X = df [train_cols]\n",
    "y = df [label]\n",
    "\n",
    "## The prepared data of the dataset is printed.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53385711",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Oversample application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5cff06",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An oversample process is applied to level the amount of existing data given by the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ec9a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The number of elements present in the grouped target is printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ff771",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Oversample application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34764303",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of the oversample to the prepared data.\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f7448",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Printing of the data after the application of the oversample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a46854",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The results obtained after applying the oversample are printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d86d7f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparation of the parameters of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebcd60b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to define the parameters necessary for the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9fa65f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06083f31",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a7a65",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The alpha parameters and the initial learning rate are adjusted to obtain the best performance with the model\n",
    "using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e41a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_normal\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = regul_param, \n",
    "             learning_rate = 'constant', learning_rate_init = 0.0001, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd95f0e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ebc4be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Alpha 10^{X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e08697",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The training is performed again keeping the same parameters except for the alpha value that changes to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318ab56",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_alpha\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = 1, \n",
    "             learning_rate = 'constant', learning_rate_init = regul_param, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402008ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e9874",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Learning Rate 10^{-X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9adbf18",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1672c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The parameters of the final model are modified according to the data obtained in the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c260905",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The value of the alpha parameter, learning_rate_init and random_state are changed according\n",
    "## to the data in the global variables.\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = alpha,\n",
    "                            learning_rate = 'constant', learning_rate_init = learning_rate_init, max_iter = 100000,\n",
    "                            random_state = random_state_model)\n",
    "\n",
    "## We print the data of the final generated model.\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441323c8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We safeguard the final generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8284bc2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(mlp,\"model_depression_i\" + str(iteration) + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53348c8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the confusion matrix of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b8a19",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We obtain the statistics of the final model to generate its confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b9410e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The data for the generation of the confession matrix are defined.\n",
    "confusion_matrix = ConfusionMatrixDisplay.from_estimator(mlp, X_test, y_test, display_labels = target_names,\n",
    "                                                         cmap = plt.cm.Blues)\n",
    "confusion_matrix.ax_.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d342c2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get the detailed statistics of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bca92d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary detailed prediction is generated.\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "## The detailed statistics of the model are printed.\n",
    "print('Classification accuracy =',accuracy_score(y_test,y_pred) * 100,'%\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0784e1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data obtained is saved for later graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0a32f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred) * 100\n",
    "clf_rep = precision_recall_fscore_support(y_test,y_pred)\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_delete = ds[ds.Status == \"Delete\"]\n",
    "ds_delete.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## All the metrics of the confusion matrix are obtained.\n",
    "metrics = [\",\".join(map(str, ds_delete['Question'].tolist())),\n",
    "           accuracy]\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    metrics.append(clf_rep[0][index])\n",
    "    metrics.append(clf_rep[1][index])\n",
    "    metrics.append(clf_rep[2][index])\n",
    "    metrics.append(clf_rep[3][index])\n",
    "\n",
    "## The names of the columns of the dataset are defined.\n",
    "columns = ['Question', 'Acurracy global']\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    columns.append('Precision_' + str(index))\n",
    "    columns.append('Recall_' + str(index))\n",
    "    columns.append('F1_score_' + str(index))\n",
    "    columns.append('Support_' + str(index))\n",
    "\n",
    "## A new row of the dataset is generated with all the data.\n",
    "data_metrics = pd.DataFrame([metrics], columns = columns)\n",
    "\n",
    "## The data is saved to the dataset.\n",
    "data_metrics.to_csv(path_dataset_qd, mode = 'a', header = False, index = False)\n",
    "\n",
    "## The data added to the dataset is printed.\n",
    "data_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab1575",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Improvement process of the neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b25d1b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The application of the explanation method by ALE allows to determine the behavior of the neural network and thereby improve it by discarding non-significant data for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c278701a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope Analysis of ALE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed27e20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d3a290",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to obtain the graphs to obtain the slopes of the selected classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db53ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The question metrics dataset is loaded.\n",
    "dm = pd.DataFrame()\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"]\n",
    "ds_item.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## We get the slopes from the ALE data.\n",
    "for i in range(df.shape[1]-1):\n",
    "    structure_data = {'Question': ds_item.loc[i, \"Question\"]}\n",
    "    \n",
    "    for index in selection_class:\n",
    "        slope = proba_exp_lr.ale_values [i][1][index] - proba_exp_lr.ale_values [i][0][index]\n",
    "        structure_data['Slope ' + str(target_names[index])] = slope\n",
    "        structure_data['Threshold ' + str(target_names[index])] = 'NA'\n",
    "        structure_data['Anomaly ' + str(target_names[index])] = 'NA'\n",
    "        \n",
    "    dm = dm.append(structure_data, ignore_index=True)\n",
    "    \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec7584",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope analysis and threshold application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b32b7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The slope obtained is analyzed and those that are above or below the positive and negative threshold are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d7ecf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## The slopes are selected according to the values of the thresholds of the defined classes.\n",
    "        if dm.loc[i, \"Slope \" + str(target_names[index])] >= positive_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 1\n",
    "        elif dm.loc[i, \"Slope \" + str(target_names[index])] <= negative_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 0\n",
    "            \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2718bf0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis and determination of anomalous items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f94ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The anomalous items present in the model are determined based on their slope and expected response from the expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486fbd09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The dataset of expected responses is loaded.\n",
    "da = pd.read_csv(path_dataset_qa)\n",
    "\n",
    "## Delete list of items deleted in this iteration.\n",
    "i = 0\n",
    "for x in ds_delete['Question']:\n",
    "    da.drop(da.index[x - (i + 1)], axis = 0, inplace = True)\n",
    "    i += 1\n",
    "\n",
    "## Indexes are restored for later use.\n",
    "da.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## The dataset of expected responses is printed.\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c4fa2b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to identify the anomadic items present in the model present in this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24392188",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    \n",
    "    ## Local variable to indicate the index of the selected classes.\n",
    "    i_index = 0\n",
    "    \n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## Determine if it fails based on the expected response parameters of the defined classes.\n",
    "        if dm.loc[i, \"Threshold \"  + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][0]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][1]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][2]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \"  + str(target_names[index])] = expected_response_map[i_index][3]\n",
    "        \n",
    "        ## Increase of the index of the selected classes.\n",
    "        i_index += 1\n",
    "\n",
    "## The final grade data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c40d75b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Removing identified anomadic items from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244d7f6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to eliminate the identified anomadic items so as not to use them in the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7059c98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variable for the elimination of the anomaly items.\n",
    "instructions = ''\n",
    "init = False\n",
    "question_anomaly = []\n",
    "\n",
    "if selection_mode == 1:\n",
    "    \n",
    "    ## Items that fail in the defined class are retrieved.\n",
    "    dm_delete = dm[dm['Anomaly ' + str(target_names[select_class_mode])] == 1]\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 2:\n",
    "    \n",
    "    ## Items that fail in classes defined with the or condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" or `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 3:\n",
    "    \n",
    "    ## Items that fail in classes defined with the and condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 4:\n",
    "    \n",
    "    ## Out-of-threshold items are retrieved in classes defined with the condition type and.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "\n",
    "## The selected blank items are printed according to the selection_mode.\n",
    "question_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aac21be",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model explainability process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436115a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data used for the test of the neural network model is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0aef5e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b70e07",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa8613",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In analysis of the model through the results obtained by ALE, it is possible to identify the behavior of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935dce70",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec0492",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graphs of all the data present in the dataset used are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c0b94",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ale(proba_exp_lr, n_cols=2, features=list(range(df.shape[1]-1)),fig_kw={'figwidth': 10, 'figheight': 180});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd944f4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c43509",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to explain the improved model using LIME for the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8370f331",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                   feature_names=train_cols, class_names=target_names, \n",
    "                                                   discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe5bf06",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d4c5b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[0], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b587c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4883c8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c554ca",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8681382",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[-1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7240e5d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71a5382",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SHAP explanatory values are displayed according to the class to which the selected individual belongs according to the prediction of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff459bf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d6d22",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[0]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc7e3f0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145fa23",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49818b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284972f3",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[-1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9887e6b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation using heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4f6dba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The importance of the data present in the neural network is shown from explanation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8c55b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Items currently in use are retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"].reset_index(drop=True)\n",
    "\n",
    "## The data is prepared for the generation of heatmaps.\n",
    "column_Map = ds_item['Question'].tolist()\n",
    "content_Map = [False for x in range(1, df.shape[1])]\n",
    "\n",
    "## The next items to be deleted will be marked.\n",
    "for index in range(0, len(content_Map)):\n",
    "    \n",
    "    if iteration == 0:\n",
    "        for delete in list_contr:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "    else:\n",
    "        for delete in question_anomaly:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "\n",
    "## The dataframe is created with the prepared data.\n",
    "df_mask = pd.DataFrame([content_Map], columns = column_Map)\n",
    "df_mask_imp = pd.concat([df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "df_mask_all = pd.concat([df_mask, df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "\n",
    "df_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392302f2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f3901",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Identification of feature variables from the randomness of the answers as items of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de460e3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Loading the data for explainability.\n",
    "explainer = ClassifierExplainer(mlp, X_test, y_test)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f9999b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa66dbd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0759ead0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576d85f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2adb52",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb25423d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dd6903",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc1043",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_importance = pd.concat(map_class, axis=1)\n",
    "df_importance.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Reds\", cbar = False)\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Blues\",yticklabels = True, xticklabels = True ,mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b0a9f0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28989a1a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49219a73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f86f0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a244c10b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbdbd15",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e597d8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f25c662",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455bae5c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708844cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438b2199",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc182c4c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfebf145",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf4c237",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b84a56",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f924cc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99b2a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ad7ee6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e16301",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1209876c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b9251",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ecce8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e4d43",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e3bba",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f67e569",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb003240",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129eff5b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b27483",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f7cdec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e7227",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916a9de3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178b0e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_shap = pd.concat(map_class, axis=1)\n",
    "df_shap.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d617de",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e664980",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5692ea2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data preparation for explainability.\n",
    "lime_exp = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                  feature_names=train_cols, class_names=target_names,\n",
    "                                                  discretize_continuous=True)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82236289",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by LIME about the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a1fbee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for LIME array data.\n",
    "exp_matrix = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for LIME.\n",
    "for x in X_test.to_numpy():\n",
    "    \n",
    "    ## Auxiliary temporary variables.\n",
    "    exp_list = [[] for _ in range(len(name_class))]\n",
    "    \n",
    "    ## Loading the data for explainability.\n",
    "    exp = lime_exp.explain_instance(x, mlp.predict_proba, num_features = df.shape[1] - 1, top_labels = len(name_class))\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "        temp = exp.as_map()[elements]\n",
    "        temp.sort(key=itemgetter(0))\n",
    "        \n",
    "        ## Saving data of the Low, Medium and High classes.\n",
    "        for tup in temp:\n",
    "            exp_list[elements].append(tup[1])\n",
    "            \n",
    "        exp_matrix[elements].append(exp_list[elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0046e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f01981f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7bc30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfce3f2e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dcc5af",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e280dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce0fbe6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01b102",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a0c59",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfdd86f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea65313",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0522a17",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14363a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d4395b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4284b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f698340",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecafba68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_lime = pd.concat(map_class, axis=1)\n",
    "df_lime.columns = name_class\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783b03c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3dd956",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It shows the main effect of each question compared to the probability that the model predicts in each class. This effect is shown for both responses. Since there are only 2 answers, the map is the same but with the colors reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db710b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names=train_cols, target_names= target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95029a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by ALE about all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cdf697",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for ALE array data.\n",
    "ale_list = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for ALE.\n",
    "for array in proba_exp_lr.ale_values:\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "    \n",
    "        ## Saving data of all the classes.\n",
    "        ale_list[elements].append(array[0][elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46b44d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data processing for the explainability of ALE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936feae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data processing of the Low, Medium and High classes.\n",
    "for elements in range(0, len(name_class)):\n",
    "    ale_df = pd.DataFrame([ale_list [elements]])\n",
    "    ale_df = pd.concat([ale_df.multiply(-1), ale_df])\n",
    "    ale_df.index = [name_class [elements] + \" - False\", name_class [elements] + \" - True\"]\n",
    "    ale_df.columns = column_Map\n",
    "    map_class.append(ale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfce9610",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c12679",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b83153",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01da21e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9842d051",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ae28f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c23ff7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99523ec8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163aeac4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839e646d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999daea3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of absolute value to data.\n",
    "for index in range(0, len(map_class)):\n",
    "    map_class [index] = map_class [index][0:1].abs()\n",
    "\n",
    "## Union of the heatmaps of the Low, Medium and High class.\n",
    "ale_df = pd.concat(map_class)\n",
    "ale_df.index = name_class\n",
    "ale_df = ale_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fdc3fa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9cd86",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask= df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98bc780",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparing of Feature Variables Methods for Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09578a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The global values of each of the methods used are taken, their maximums are obtained (the minimums are 0) and a percentage is calculated based on said maximum, which indicates how relevant the contribution is for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73778845",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a399f700",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c08030",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e66c2df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d37540",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1453fa5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2506e205",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b66d543",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044d800e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be647a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322cd5cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8521f1bd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f7d7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b9e878",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720098ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b17f77d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18739dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e21f73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733dd8af",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c100605",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a98ea79",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d057f308",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5089ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Safeguarding the items eliminated during this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f469118",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Removal of anomalous items selected by selection_mode.\n",
    "for x in question_anomaly:\n",
    "\n",
    "    ## Status change of the deleted items in the respective auxiliary dataset.\n",
    "    ds.loc[x - 1,'Status'] = 'Delete'\n",
    "\n",
    "## Save the changed statuses in the dataset.\n",
    "ds.to_csv(path_dataset_qs, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b875c3d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iteration 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b70da22",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first iteration of improvement of the model is carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f98f74",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing the data for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c5bb51",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data is prepared in order to be processed by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917e0b7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The iteration number is increased.\n",
    "iteration += 1\n",
    "\n",
    "## Loading data from the dataset.\n",
    "df = pd.read_csv(path_dataset)\n",
    "ds = pd.read_csv(path_dataset_qs)\n",
    "\n",
    "## Elimination of unrelated items from the dataset.\n",
    "if len(unrelated_questions) != 0:\n",
    "    df = df.drop(df.columns[unrelated_questions[0]:unrelated_questions[1]], axis=1)\n",
    "\n",
    "i = 0\n",
    "if iteration == 1:\n",
    "    ## Elimination of list of conflicting items declared in global variables.\n",
    "    for x in list_contr:\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "        ## Status change of the deleted question in the respective auxiliary dataset.\n",
    "        ds.loc[x - 1,'Status'] = 'Delete'\n",
    "    \n",
    "else:    \n",
    "    ## Elimination of the list of anomadic items defined in the improvement process.\n",
    "    ds_delete = ds[ds.Status == \"Delete\"].reset_index(drop=True)\n",
    "    for x in ds_delete['Question'].tolist():\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "\n",
    "## Grouping of the target according to the defined dictionary.\n",
    "if grouping_name != None and grouping_name != '':\n",
    "    df[grouping_name] = df[grouping_name].map(class_dic)\n",
    "\n",
    "## Assignment of local variables according to the data necessary for the neural network.\n",
    "train_cols = df.columns [0:-1]\n",
    "label = df.columns [-1]\n",
    "X = df [train_cols]\n",
    "y = df [label]\n",
    "\n",
    "## The prepared data of the dataset is printed.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fc7ca5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Oversample application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d05ab0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An oversample process is applied to level the amount of existing data given by the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec532e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The number of elements present in the grouped target is printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce12cf49",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Oversample application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18289404",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of the oversample to the prepared data.\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a139f117",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Printing of the data after the application of the oversample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9f62c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The results obtained after applying the oversample are printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9dafc0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparation of the parameters of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab0535",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to define the parameters necessary for the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c017a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17416294",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f478379",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The alpha parameters and the initial learning rate are adjusted to obtain the best performance with the model\n",
    "using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6c9d34",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_normal\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = regul_param, \n",
    "             learning_rate = 'constant', learning_rate_init = 0.0001, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cff7ed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f2197",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Alpha 10^{X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6339d125",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The training is performed again keeping the same parameters except for the alpha value that changes to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d5c78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_alpha\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = 1, \n",
    "             learning_rate = 'constant', learning_rate_init = regul_param, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f6b745",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7af298",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Learning Rate 10^{-X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e8515",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0d7215",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The parameters of the final model are modified according to the data obtained in the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4042366",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The value of the alpha parameter, learning_rate_init and random_state are changed according\n",
    "## to the data in the global variables.\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = alpha,\n",
    "                            learning_rate = 'constant', learning_rate_init = learning_rate_init, max_iter = 100000,\n",
    "                            random_state = random_state_model)\n",
    "\n",
    "## We print the data of the final generated model.\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9170edc9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We safeguard the final generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372cceeb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(mlp,\"model_depression_i\" + str(iteration) + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9358f60",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the confusion matrix of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f21ca95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We obtain the statistics of the final model to generate its confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c625377a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The data for the generation of the confession matrix are defined.\n",
    "confusion_matrix = ConfusionMatrixDisplay.from_estimator(mlp, X_test, y_test, display_labels = target_names,\n",
    "                                                         cmap = plt.cm.Blues)\n",
    "confusion_matrix.ax_.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed61a8d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get the detailed statistics of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6647acbc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary detailed prediction is generated.\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "## The detailed statistics of the model are printed.\n",
    "print('Classification accuracy =',accuracy_score(y_test,y_pred) * 100,'%\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c802e0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data obtained is saved for later graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88554c4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred) * 100\n",
    "clf_rep = precision_recall_fscore_support(y_test,y_pred)\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_delete = ds[ds.Status == \"Delete\"]\n",
    "ds_delete.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## All the metrics of the confusion matrix are obtained.\n",
    "metrics = [\",\".join(map(str, ds_delete['Question'].tolist())),\n",
    "           accuracy]\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    metrics.append(clf_rep[0][index])\n",
    "    metrics.append(clf_rep[1][index])\n",
    "    metrics.append(clf_rep[2][index])\n",
    "    metrics.append(clf_rep[3][index])\n",
    "\n",
    "## The names of the columns of the dataset are defined.\n",
    "columns = ['Question', 'Acurracy global']\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    columns.append('Precision_' + str(index))\n",
    "    columns.append('Recall_' + str(index))\n",
    "    columns.append('F1_score_' + str(index))\n",
    "    columns.append('Support_' + str(index))\n",
    "\n",
    "## A new row of the dataset is generated with all the data.\n",
    "data_metrics = pd.DataFrame([metrics], columns = columns)\n",
    "\n",
    "## The data is saved to the dataset.\n",
    "data_metrics.to_csv(path_dataset_qd, mode = 'a', header = False, index = False)\n",
    "\n",
    "## The data added to the dataset is printed.\n",
    "data_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25b4e63",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Improvement process of the neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd924a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The application of the explanation method by ALE allows to determine the behavior of the neural network and thereby improve it by discarding non-significant data for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea9f4f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope Analysis of ALE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41e1fa8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65226cb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to obtain the graphs to obtain the slopes of the selected classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed27cd3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The question metrics dataset is loaded.\n",
    "dm = pd.DataFrame()\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"]\n",
    "ds_item.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## We get the slopes from the ALE data.\n",
    "for i in range(df.shape[1]-1):\n",
    "    structure_data = {'Question': ds_item.loc[i, \"Question\"]}\n",
    "    \n",
    "    for index in selection_class:\n",
    "        slope = proba_exp_lr.ale_values [i][1][index] - proba_exp_lr.ale_values [i][0][index]\n",
    "        structure_data['Slope ' + str(target_names[index])] = slope\n",
    "        structure_data['Threshold ' + str(target_names[index])] = 'NA'\n",
    "        structure_data['Anomaly ' + str(target_names[index])] = 'NA'\n",
    "        \n",
    "    dm = dm.append(structure_data, ignore_index=True)\n",
    "    \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c4385",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope analysis and threshold application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd547a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The slope obtained is analyzed and those that are above or below the positive and negative threshold are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d2540",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## The slopes are selected according to the values of the thresholds of the defined classes.\n",
    "        if dm.loc[i, \"Slope \" + str(target_names[index])] >= positive_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 1\n",
    "        elif dm.loc[i, \"Slope \" + str(target_names[index])] <= negative_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 0\n",
    "            \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe431aa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis and determination of anomalous items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cbabeb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The anomalous items present in the model are determined based on their slope and expected response from the expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e2ac9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The dataset of expected responses is loaded.\n",
    "da = pd.read_csv(path_dataset_qa)\n",
    "\n",
    "## Delete list of items deleted in this iteration.\n",
    "i = 0\n",
    "for x in ds_delete['Question']:\n",
    "    da.drop(da.index[x - (i + 1)], axis = 0, inplace = True)\n",
    "    i += 1\n",
    "\n",
    "## Indexes are restored for later use.\n",
    "da.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## The dataset of expected responses is printed.\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca13e48",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to identify the anomadic items present in the model present in this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9168c6a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    \n",
    "    ## Local variable to indicate the index of the selected classes.\n",
    "    i_index = 0\n",
    "    \n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## Determine if it fails based on the expected response parameters of the defined classes.\n",
    "        if dm.loc[i, \"Threshold \"  + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][0]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][1]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][2]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \"  + str(target_names[index])] = expected_response_map[i_index][3]\n",
    "        \n",
    "        ## Increase of the index of the selected classes.\n",
    "        i_index += 1\n",
    "\n",
    "## The final grade data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385157d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Removing identified anomadic items from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa1cdd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to eliminate the identified anomadic items so as not to use them in the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e159da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variable for the elimination of the anomaly items.\n",
    "instructions = ''\n",
    "init = False\n",
    "question_anomaly = []\n",
    "\n",
    "if selection_mode == 1:\n",
    "    \n",
    "    ## Items that fail in the defined class are retrieved.\n",
    "    dm_delete = dm[dm['Anomaly ' + str(target_names[select_class_mode])] == 1]\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 2:\n",
    "    \n",
    "    ## Items that fail in classes defined with the or condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" or `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 3:\n",
    "    \n",
    "    ## Items that fail in classes defined with the and condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 4:\n",
    "    \n",
    "    ## Out-of-threshold items are retrieved in classes defined with the condition type and.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "\n",
    "## The selected blank items are printed according to the selection_mode.\n",
    "question_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb6812",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model explainability process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcafc8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data used for the test of the neural network model is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3c29e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c413c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086490f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In analysis of the model through the results obtained by ALE, it is possible to identify the behavior of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f540f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4220f0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graphs of all the data present in the dataset used are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f1370",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ale(proba_exp_lr, n_cols=2, features=list(range(df.shape[1]-1)),fig_kw={'figwidth': 10, 'figheight': 180});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd4b50d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc62dd0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to explain the improved model using LIME for the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8609ebe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                   feature_names=train_cols, class_names=target_names, \n",
    "                                                   discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910f419",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b6640a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[0], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6963bc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c7d39",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b903839",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fddf2f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[-1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2a2614",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fe9d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SHAP explanatory values are displayed according to the class to which the selected individual belongs according to the prediction of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488be18",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf2202",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[0]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7920c84",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7333ce",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11b638",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082aed09",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[-1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f672a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation using heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ce8f3b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The importance of the data present in the neural network is shown from explanation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387cb14",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Items currently in use are retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"].reset_index(drop=True)\n",
    "\n",
    "## The data is prepared for the generation of heatmaps.\n",
    "column_Map = ds_item['Question'].tolist()\n",
    "content_Map = [False for x in range(1, df.shape[1])]\n",
    "\n",
    "## The next items to be deleted will be marked.\n",
    "for index in range(0, len(content_Map)):\n",
    "    \n",
    "    if iteration == 0:\n",
    "        for delete in list_contr:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "    else:\n",
    "        for delete in question_anomaly:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "\n",
    "## The dataframe is created with the prepared data.\n",
    "df_mask = pd.DataFrame([content_Map], columns = column_Map)\n",
    "df_mask_imp = pd.concat([df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "df_mask_all = pd.concat([df_mask, df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "\n",
    "df_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f566f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7f9545",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Identification of feature variables from the randomness of the answers as items of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a169990",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Loading the data for explainability.\n",
    "explainer = ClassifierExplainer(mlp, X_test, y_test)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3210e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc485df3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b0e83",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4088e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5c226",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddbb3b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca50257",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7949f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_importance = pd.concat(map_class, axis=1)\n",
    "df_importance.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Reds\", cbar = False)\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Blues\",yticklabels = True, xticklabels = True ,mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32252b9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbae463",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78732f72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc00d0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d64cf1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef219517",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727f5a6e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71720e4d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5a63f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115c950",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7be59b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbefb9d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2811d86",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83fb853",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8369b36",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c14e7d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e9e06",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc875823",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99245c5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2490f1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00277316",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee73c08",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42cfb69",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61795f25",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed6df0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca81db4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7659ddda",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248e568",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00259f45",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f4e75",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709fd617",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdda0db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_shap = pd.concat(map_class, axis=1)\n",
    "df_shap.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b669b1a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc536036",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416fad46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data preparation for explainability.\n",
    "lime_exp = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                  feature_names=train_cols, class_names=target_names,\n",
    "                                                  discretize_continuous=True)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b7469",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by LIME about the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1b4ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for LIME array data.\n",
    "exp_matrix = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for LIME.\n",
    "for x in X_test.to_numpy():\n",
    "    \n",
    "    ## Auxiliary temporary variables.\n",
    "    exp_list = [[] for _ in range(len(name_class))]\n",
    "    \n",
    "    ## Loading the data for explainability.\n",
    "    exp = lime_exp.explain_instance(x, mlp.predict_proba, num_features = df.shape[1] - 1, top_labels = len(name_class))\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "        temp = exp.as_map()[elements]\n",
    "        temp.sort(key=itemgetter(0))\n",
    "        \n",
    "        ## Saving data of the Low, Medium and High classes.\n",
    "        for tup in temp:\n",
    "            exp_list[elements].append(tup[1])\n",
    "            \n",
    "        exp_matrix[elements].append(exp_list[elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba45bead",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f094cf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94412547",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1bb18",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7662d6c2",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004bb9f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e5d389",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b3d5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d39af",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322456b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc5bbbc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd00ff4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87212537",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a93a2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d2f73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da9acd9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06067699",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_lime = pd.concat(map_class, axis=1)\n",
    "df_lime.columns = name_class\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d88348",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44d862",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It shows the main effect of each question compared to the probability that the model predicts in each class. This effect is shown for both responses. Since there are only 2 answers, the map is the same but with the colors reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ca177",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names=train_cols, target_names= target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c6c074",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by ALE about all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a2835",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for ALE array data.\n",
    "ale_list = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for ALE.\n",
    "for array in proba_exp_lr.ale_values:\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "    \n",
    "        ## Saving data of all the classes.\n",
    "        ale_list[elements].append(array[0][elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8731a1d6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data processing for the explainability of ALE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11f7d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data processing of the Low, Medium and High classes.\n",
    "for elements in range(0, len(name_class)):\n",
    "    ale_df = pd.DataFrame([ale_list [elements]])\n",
    "    ale_df = pd.concat([ale_df.multiply(-1), ale_df])\n",
    "    ale_df.index = [name_class [elements] + \" - False\", name_class [elements] + \" - True\"]\n",
    "    ale_df.columns = column_Map\n",
    "    map_class.append(ale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672e2a68",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54405235",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c43087",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7f1e5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d3642b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198939f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639ae87",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec05d81",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feadadb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4ac7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbebbf9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of absolute value to data.\n",
    "for index in range(0, len(map_class)):\n",
    "    map_class [index] = map_class [index][0:1].abs()\n",
    "\n",
    "## Union of the heatmaps of the Low, Medium and High class.\n",
    "ale_df = pd.concat(map_class)\n",
    "ale_df.index = name_class\n",
    "ale_df = ale_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc651bd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b170ca43",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask= df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf512cc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparing of Feature Variables Methods for Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515650a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The global values of each of the methods used are taken, their maximums are obtained (the minimums are 0) and a percentage is calculated based on said maximum, which indicates how relevant the contribution is for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4258f0e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e83e7d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79683c8c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4141a26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b676e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606356a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa82dbd4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b4606",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbcd062",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a047a7af",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5395e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac0bb81",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441324c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68830c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9165692",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc50ca97",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6bc345",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2044cc0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5ffc6e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee90ce7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e6d9ee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808eb73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093b9e64",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Safeguarding the items eliminated during this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7185bc96",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Removal of anomalous items selected by selection_mode.\n",
    "for x in question_anomaly:\n",
    "\n",
    "    ## Status change of the deleted items in the respective auxiliary dataset.\n",
    "    ds.loc[x - 1,'Status'] = 'Delete'\n",
    "\n",
    "## Save the changed statuses in the dataset.\n",
    "ds.to_csv(path_dataset_qs, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fbe2fe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iteration 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eb7f01",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first iteration of improvement of the model is carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be0654f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing the data for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936fdee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data is prepared in order to be processed by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cee080",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The iteration number is increased.\n",
    "iteration += 1\n",
    "\n",
    "## Loading data from the dataset.\n",
    "df = pd.read_csv(path_dataset)\n",
    "ds = pd.read_csv(path_dataset_qs)\n",
    "\n",
    "## Elimination of unrelated items from the dataset.\n",
    "if len(unrelated_questions) != 0:\n",
    "    df = df.drop(df.columns[unrelated_questions[0]:unrelated_questions[1]], axis=1)\n",
    "\n",
    "i = 0\n",
    "if iteration == 1:\n",
    "    ## Elimination of list of conflicting items declared in global variables.\n",
    "    for x in list_contr:\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "        ## Status change of the deleted question in the respective auxiliary dataset.\n",
    "        ds.loc[x - 1,'Status'] = 'Delete'\n",
    "    \n",
    "else:    \n",
    "    ## Elimination of the list of anomadic items defined in the improvement process.\n",
    "    ds_delete = ds[ds.Status == \"Delete\"].reset_index(drop=True)\n",
    "    for x in ds_delete['Question'].tolist():\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "\n",
    "## Grouping of the target according to the defined dictionary.\n",
    "if grouping_name != None and grouping_name != '':\n",
    "    df[grouping_name] = df[grouping_name].map(class_dic)\n",
    "\n",
    "## Assignment of local variables according to the data necessary for the neural network.\n",
    "train_cols = df.columns [0:-1]\n",
    "label = df.columns [-1]\n",
    "X = df [train_cols]\n",
    "y = df [label]\n",
    "\n",
    "## The prepared data of the dataset is printed.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee647f5b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Oversample application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab0581",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An oversample process is applied to level the amount of existing data given by the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f92df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The number of elements present in the grouped target is printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6015a10",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Oversample application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb372729",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of the oversample to the prepared data.\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a337b93",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Printing of the data after the application of the oversample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0afbaf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The results obtained after applying the oversample are printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991c418",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparation of the parameters of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c940e0c2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to define the parameters necessary for the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6addca8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a7279f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808492bd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The alpha parameters and the initial learning rate are adjusted to obtain the best performance with the model\n",
    "using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf9d497",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_normal\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = regul_param, \n",
    "             learning_rate = 'constant', learning_rate_init = 0.0001, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beedb0a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7d3ea2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Alpha 10^{X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f67d8f6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The training is performed again keeping the same parameters except for the alpha value that changes to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe3e42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_alpha\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = 1, \n",
    "             learning_rate = 'constant', learning_rate_init = regul_param, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40e818",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ab336",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Learning Rate 10^{-X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb75f4ab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740aa74",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The parameters of the final model are modified according to the data obtained in the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f27d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The value of the alpha parameter, learning_rate_init and random_state are changed according\n",
    "## to the data in the global variables.\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = alpha,\n",
    "                            learning_rate = 'constant', learning_rate_init = learning_rate_init, max_iter = 100000,\n",
    "                            random_state = random_state_model)\n",
    "\n",
    "## We print the data of the final generated model.\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b95a4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We safeguard the final generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02cd19f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(mlp,\"model_depression_i\" + str(iteration) + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f312b5c8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the confusion matrix of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa11e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We obtain the statistics of the final model to generate its confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda086a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The data for the generation of the confession matrix are defined.\n",
    "confusion_matrix = ConfusionMatrixDisplay.from_estimator(mlp, X_test, y_test, display_labels = target_names,\n",
    "                                                         cmap = plt.cm.Blues)\n",
    "confusion_matrix.ax_.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e229ab1e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get the detailed statistics of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d0e2e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary detailed prediction is generated.\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "## The detailed statistics of the model are printed.\n",
    "print('Classification accuracy =',accuracy_score(y_test,y_pred) * 100,'%\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8e35a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data obtained is saved for later graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225fda0d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred) * 100\n",
    "clf_rep = precision_recall_fscore_support(y_test,y_pred)\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_delete = ds[ds.Status == \"Delete\"]\n",
    "ds_delete.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## All the metrics of the confusion matrix are obtained.\n",
    "metrics = [\",\".join(map(str, ds_delete['Question'].tolist())),\n",
    "           accuracy]\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    metrics.append(clf_rep[0][index])\n",
    "    metrics.append(clf_rep[1][index])\n",
    "    metrics.append(clf_rep[2][index])\n",
    "    metrics.append(clf_rep[3][index])\n",
    "\n",
    "## The names of the columns of the dataset are defined.\n",
    "columns = ['Question', 'Acurracy global']\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    columns.append('Precision_' + str(index))\n",
    "    columns.append('Recall_' + str(index))\n",
    "    columns.append('F1_score_' + str(index))\n",
    "    columns.append('Support_' + str(index))\n",
    "\n",
    "## A new row of the dataset is generated with all the data.\n",
    "data_metrics = pd.DataFrame([metrics], columns = columns)\n",
    "\n",
    "## The data is saved to the dataset.\n",
    "data_metrics.to_csv(path_dataset_qd, mode = 'a', header = False, index = False)\n",
    "\n",
    "## The data added to the dataset is printed.\n",
    "data_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b341424c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Improvement process of the neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daa44d9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The application of the explanation method by ALE allows to determine the behavior of the neural network and thereby improve it by discarding non-significant data for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22697a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope Analysis of ALE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa593e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd78979b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to obtain the graphs to obtain the slopes of the selected classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77fd04e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The question metrics dataset is loaded.\n",
    "dm = pd.DataFrame()\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"]\n",
    "ds_item.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## We get the slopes from the ALE data.\n",
    "for i in range(df.shape[1]-1):\n",
    "    structure_data = {'Question': ds_item.loc[i, \"Question\"]}\n",
    "    \n",
    "    for index in selection_class:\n",
    "        slope = proba_exp_lr.ale_values [i][1][index] - proba_exp_lr.ale_values [i][0][index]\n",
    "        structure_data['Slope ' + str(target_names[index])] = slope\n",
    "        structure_data['Threshold ' + str(target_names[index])] = 'NA'\n",
    "        structure_data['Anomaly ' + str(target_names[index])] = 'NA'\n",
    "        \n",
    "    dm = dm.append(structure_data, ignore_index=True)\n",
    "    \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb91b3b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope analysis and threshold application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf5926",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The slope obtained is analyzed and those that are above or below the positive and negative threshold are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e15e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## The slopes are selected according to the values of the thresholds of the defined classes.\n",
    "        if dm.loc[i, \"Slope \" + str(target_names[index])] >= positive_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 1\n",
    "        elif dm.loc[i, \"Slope \" + str(target_names[index])] <= negative_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 0\n",
    "            \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aab1c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis and determination of anomalous items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607f0fb5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The anomalous items present in the model are determined based on their slope and expected response from the expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d02bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The dataset of expected responses is loaded.\n",
    "da = pd.read_csv(path_dataset_qa)\n",
    "\n",
    "## Delete list of items deleted in this iteration.\n",
    "i = 0\n",
    "for x in ds_delete['Question']:\n",
    "    da.drop(da.index[x - (i + 1)], axis = 0, inplace = True)\n",
    "    i += 1\n",
    "\n",
    "## Indexes are restored for later use.\n",
    "da.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## The dataset of expected responses is printed.\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2903ccb5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to identify the anomadic items present in the model present in this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a1547",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    \n",
    "    ## Local variable to indicate the index of the selected classes.\n",
    "    i_index = 0\n",
    "    \n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## Determine if it fails based on the expected response parameters of the defined classes.\n",
    "        if dm.loc[i, \"Threshold \"  + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][0]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][1]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][2]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \"  + str(target_names[index])] = expected_response_map[i_index][3]\n",
    "        \n",
    "        ## Increase of the index of the selected classes.\n",
    "        i_index += 1\n",
    "\n",
    "## The final grade data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3831a25e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Removing identified anomadic items from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22825d22",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to eliminate the identified anomadic items so as not to use them in the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1b981",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variable for the elimination of the anomaly items.\n",
    "instructions = ''\n",
    "init = False\n",
    "question_anomaly = []\n",
    "\n",
    "if selection_mode == 1:\n",
    "    \n",
    "    ## Items that fail in the defined class are retrieved.\n",
    "    dm_delete = dm[dm['Anomaly ' + str(target_names[select_class_mode])] == 1]\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 2:\n",
    "    \n",
    "    ## Items that fail in classes defined with the or condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" or `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 3:\n",
    "    \n",
    "    ## Items that fail in classes defined with the and condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 4:\n",
    "    \n",
    "    ## Out-of-threshold items are retrieved in classes defined with the condition type and.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "\n",
    "## The selected blank items are printed according to the selection_mode.\n",
    "question_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb305827",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model explainability process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d5ed93",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data used for the test of the neural network model is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347e513",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8093e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4128f39f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In analysis of the model through the results obtained by ALE, it is possible to identify the behavior of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ea423",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9cc735",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graphs of all the data present in the dataset used are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd861575",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ale(proba_exp_lr, n_cols=2, features=list(range(df.shape[1]-1)),fig_kw={'figwidth': 10, 'figheight': 180});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6676d38a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e56257",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to explain the improved model using LIME for the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6208bef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                   feature_names=train_cols, class_names=target_names, \n",
    "                                                   discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a916872",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b83b60",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[0], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d98b77",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d3fa4b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bb89d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e09ba57",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[-1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a7fb8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db133fe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SHAP explanatory values are displayed according to the class to which the selected individual belongs according to the prediction of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffd98f8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f8f0d9",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[0]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b063868",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567bb05",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4fe67a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a08d1",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[-1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c512f38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation using heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b4ebe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The importance of the data present in the neural network is shown from explanation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a21c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Items currently in use are retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"].reset_index(drop=True)\n",
    "\n",
    "## The data is prepared for the generation of heatmaps.\n",
    "column_Map = ds_item['Question'].tolist()\n",
    "content_Map = [False for x in range(1, df.shape[1])]\n",
    "\n",
    "## The next items to be deleted will be marked.\n",
    "for index in range(0, len(content_Map)):\n",
    "    \n",
    "    if iteration == 0:\n",
    "        for delete in list_contr:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "    else:\n",
    "        for delete in question_anomaly:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "\n",
    "## The dataframe is created with the prepared data.\n",
    "df_mask = pd.DataFrame([content_Map], columns = column_Map)\n",
    "df_mask_imp = pd.concat([df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "df_mask_all = pd.concat([df_mask, df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "\n",
    "df_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5ace9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa5132",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Identification of feature variables from the randomness of the answers as items of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9bf6e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Loading the data for explainability.\n",
    "explainer = ClassifierExplainer(mlp, X_test, y_test)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4179cb11",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d50c8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b06ed5d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef6200",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38960ad5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c21acc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc772606",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ddfd7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_importance = pd.concat(map_class, axis=1)\n",
    "df_importance.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Reds\", cbar = False)\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Blues\",yticklabels = True, xticklabels = True ,mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caddebce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c57123",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e043a772",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242e3b94",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c28362",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48ac5a",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10844795",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2c107",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaf1227",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86e88a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e2caf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3dc35d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e6822",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e155d71",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea403d",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106f595",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab38c4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5274a92",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb75f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f1a71",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b357a56",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eace0b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac56b79",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb5ddd8",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ef30d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a06fa0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f680d43",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb526a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a7c0c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e4db1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3592857",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e60a8e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_shap = pd.concat(map_class, axis=1)\n",
    "df_shap.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212af858",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6bb02",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0dc511",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data preparation for explainability.\n",
    "lime_exp = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                  feature_names=train_cols, class_names=target_names,\n",
    "                                                  discretize_continuous=True)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eefbbc7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by LIME about the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf958e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for LIME array data.\n",
    "exp_matrix = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for LIME.\n",
    "for x in X_test.to_numpy():\n",
    "    \n",
    "    ## Auxiliary temporary variables.\n",
    "    exp_list = [[] for _ in range(len(name_class))]\n",
    "    \n",
    "    ## Loading the data for explainability.\n",
    "    exp = lime_exp.explain_instance(x, mlp.predict_proba, num_features = df.shape[1] - 1, top_labels = len(name_class))\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "        temp = exp.as_map()[elements]\n",
    "        temp.sort(key=itemgetter(0))\n",
    "        \n",
    "        ## Saving data of the Low, Medium and High classes.\n",
    "        for tup in temp:\n",
    "            exp_list[elements].append(tup[1])\n",
    "            \n",
    "        exp_matrix[elements].append(exp_list[elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de472f05",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10db9a1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2f33b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7dbf9e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d649e45",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f923f73",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad5a7c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1dbf58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05deec4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82cb3f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81417448",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9250e16",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdcc789",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f31cd4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973968e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7227dc68",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d8ffc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_lime = pd.concat(map_class, axis=1)\n",
    "df_lime.columns = name_class\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1ae84f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bbeea5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It shows the main effect of each question compared to the probability that the model predicts in each class. This effect is shown for both responses. Since there are only 2 answers, the map is the same but with the colors reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d08924",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names=train_cols, target_names= target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df99272e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by ALE about all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a08b61b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for ALE array data.\n",
    "ale_list = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for ALE.\n",
    "for array in proba_exp_lr.ale_values:\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "    \n",
    "        ## Saving data of all the classes.\n",
    "        ale_list[elements].append(array[0][elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ac9ee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data processing for the explainability of ALE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd82fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data processing of the Low, Medium and High classes.\n",
    "for elements in range(0, len(name_class)):\n",
    "    ale_df = pd.DataFrame([ale_list [elements]])\n",
    "    ale_df = pd.concat([ale_df.multiply(-1), ale_df])\n",
    "    ale_df.index = [name_class [elements] + \" - False\", name_class [elements] + \" - True\"]\n",
    "    ale_df.columns = column_Map\n",
    "    map_class.append(ale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8bb290",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4a6e76",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22cfb2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bfe57a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82f019",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e6f5ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e45e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f46ba7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9096e867",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a43fcb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52549b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of absolute value to data.\n",
    "for index in range(0, len(map_class)):\n",
    "    map_class [index] = map_class [index][0:1].abs()\n",
    "\n",
    "## Union of the heatmaps of the Low, Medium and High class.\n",
    "ale_df = pd.concat(map_class)\n",
    "ale_df.index = name_class\n",
    "ale_df = ale_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a950d2b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08edba74",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask= df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b014d4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparing of Feature Variables Methods for Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4017de60",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The global values of each of the methods used are taken, their maximums are obtained (the minimums are 0) and a percentage is calculated based on said maximum, which indicates how relevant the contribution is for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62931d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a08a810",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c9dff7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03bd732",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808f5c50",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805317f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cc4c6a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77f2864",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f0ded6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29d86a6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2a94c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca3198",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92189a79",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a5443b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d5ba5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7633728d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd33c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554e5c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f38a24e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643a581",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f58d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d45e7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd17e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Safeguarding the items eliminated during this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96337f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Removal of anomalous items selected by selection_mode.\n",
    "for x in question_anomaly:\n",
    "\n",
    "    ## Status change of the deleted items in the respective auxiliary dataset.\n",
    "    ds.loc[x - 1,'Status'] = 'Delete'\n",
    "\n",
    "## Save the changed statuses in the dataset.\n",
    "ds.to_csv(path_dataset_qs, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c73231",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iteration 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295a2830",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first iteration of improvement of the model is carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d05ebf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing the data for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e93f70",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data is prepared in order to be processed by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc511ba6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The iteration number is increased.\n",
    "iteration += 1\n",
    "\n",
    "## Loading data from the dataset.\n",
    "df = pd.read_csv(path_dataset)\n",
    "ds = pd.read_csv(path_dataset_qs)\n",
    "\n",
    "## Elimination of unrelated items from the dataset.\n",
    "if len(unrelated_questions) != 0:\n",
    "    df = df.drop(df.columns[unrelated_questions[0]:unrelated_questions[1]], axis=1)\n",
    "\n",
    "i = 0\n",
    "if iteration == 1:\n",
    "    ## Elimination of list of conflicting items declared in global variables.\n",
    "    for x in list_contr:\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "        ## Status change of the deleted question in the respective auxiliary dataset.\n",
    "        ds.loc[x - 1,'Status'] = 'Delete'\n",
    "    \n",
    "else:    \n",
    "    ## Elimination of the list of anomadic items defined in the improvement process.\n",
    "    ds_delete = ds[ds.Status == \"Delete\"].reset_index(drop=True)\n",
    "    for x in ds_delete['Question'].tolist():\n",
    "        df.drop(df.columns[x - (i + 1)], axis = 1, inplace = True)\n",
    "        i += 1\n",
    "\n",
    "## Grouping of the target according to the defined dictionary.\n",
    "if grouping_name != None and grouping_name != '':\n",
    "    df[grouping_name] = df[grouping_name].map(class_dic)\n",
    "\n",
    "## Assignment of local variables according to the data necessary for the neural network.\n",
    "train_cols = df.columns [0:-1]\n",
    "label = df.columns [-1]\n",
    "X = df [train_cols]\n",
    "y = df [label]\n",
    "\n",
    "## The prepared data of the dataset is printed.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae698412",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Oversample application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86357b8d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "An oversample process is applied to level the amount of existing data given by the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698bb27c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The number of elements present in the grouped target is printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f3ad2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Oversample application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46de5e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of the oversample to the prepared data.\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b80486",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Printing of the data after the application of the oversample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be3ab7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The results obtained after applying the oversample are printed.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b71b77",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparation of the parameters of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d65523",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to define the parameters necessary for the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702f0db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5fd37",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9078f03c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The alpha parameters and the initial learning rate are adjusted to obtain the best performance with the model\n",
    "using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a270fa1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_normal\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = regul_param, \n",
    "             learning_rate = 'constant', learning_rate_init = 0.0001, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a4b7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97fe5df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Alpha 10^{X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667fec50",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The training is performed again keeping the same parameters except for the alpha value that changes to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adce337",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables are defined for the storage of the scores obtained by the training.\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "regul_param_range = regul_param_alpha\n",
    "\n",
    "## Training and validation of different configurations.\n",
    "for regul_param in regul_param_range:\n",
    "    \n",
    "    ## Increase the max_iter parameter until it converges.\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = 1, \n",
    "             learning_rate = 'constant', learning_rate_init = regul_param, max_iter = 100000, random_state = seed)\n",
    "    \n",
    "    scores = cross_val_score(mlp, X, y, cv = 5, scoring = 'f1_macro')\n",
    "    \n",
    "    cv_scores_mean.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    \n",
    "## The results obtained during the training are printed.\n",
    "cv_scores_mean, cv_scores_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64976d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to draw the learning curve graph according to the data obtained by the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee32803",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The average accuracy line is drawn on the test parts.\n",
    "plt.figure()\n",
    "plt.plot(np.log10(regul_param_range), cv_scores_mean, color = \"g\", label = \"Test\")\n",
    "\n",
    "## The standard deviation band is drawn.\n",
    "lower_limit = np.array(cv_scores_mean) - np.array(cv_scores_std)\n",
    "upper_limit = np.array(cv_scores_mean) + np.array(cv_scores_std)\n",
    "plt.fill_between(np.log10(regul_param_range), lower_limit, upper_limit, color = \"#DDDDDD\")\n",
    "\n",
    "## Generate the graph.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Learning Rate 10^{-X}\"), plt.ylabel(\"F1\"), plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f14332a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406510e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The parameters of the final model are modified according to the data obtained in the training of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de6095e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The value of the alpha parameter, learning_rate_init and random_state are changed according\n",
    "## to the data in the global variables.\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = alpha,\n",
    "                            learning_rate = 'constant', learning_rate_init = learning_rate_init, max_iter = 100000,\n",
    "                            random_state = random_state_model)\n",
    "\n",
    "## We print the data of the final generated model.\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec67ae8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We safeguard the final generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868d739",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(mlp,\"model_depression_i\" + str(iteration) + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0aa4ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of the confusion matrix of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9a8e91",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We obtain the statistics of the final model to generate its confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1148e12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The data for the generation of the confession matrix are defined.\n",
    "confusion_matrix = ConfusionMatrixDisplay.from_estimator(mlp, X_test, y_test, display_labels = target_names,\n",
    "                                                         cmap = plt.cm.Blues)\n",
    "confusion_matrix.ax_.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49339c26",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We get the detailed statistics of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a532f7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary detailed prediction is generated.\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "## The detailed statistics of the model are printed.\n",
    "print('Classification accuracy =',accuracy_score(y_test,y_pred) * 100,'%\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c0baf7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data obtained is saved for later graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb5aa5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred) * 100\n",
    "clf_rep = precision_recall_fscore_support(y_test,y_pred)\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_delete = ds[ds.Status == \"Delete\"]\n",
    "ds_delete.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## All the metrics of the confusion matrix are obtained.\n",
    "metrics = [\",\".join(map(str, ds_delete['Question'].tolist())),\n",
    "           accuracy]\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    metrics.append(clf_rep[0][index])\n",
    "    metrics.append(clf_rep[1][index])\n",
    "    metrics.append(clf_rep[2][index])\n",
    "    metrics.append(clf_rep[3][index])\n",
    "\n",
    "## The names of the columns of the dataset are defined.\n",
    "columns = ['Question', 'Acurracy global']\n",
    "\n",
    "for index in range(0, len(name_class)):\n",
    "    columns.append('Precision_' + str(index))\n",
    "    columns.append('Recall_' + str(index))\n",
    "    columns.append('F1_score_' + str(index))\n",
    "    columns.append('Support_' + str(index))\n",
    "\n",
    "## A new row of the dataset is generated with all the data.\n",
    "data_metrics = pd.DataFrame([metrics], columns = columns)\n",
    "\n",
    "## The data is saved to the dataset.\n",
    "data_metrics.to_csv(path_dataset_qd, mode = 'a', header = False, index = False)\n",
    "\n",
    "## The data added to the dataset is printed.\n",
    "data_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923ab29",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Improvement process of the neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f60fbf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The application of the explanation method by ALE allows to determine the behavior of the neural network and thereby improve it by discarding non-significant data for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb93762",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope Analysis of ALE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb027313",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3191e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to obtain the graphs to obtain the slopes of the selected classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459e33c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The question metrics dataset is loaded.\n",
    "dm = pd.DataFrame()\n",
    "\n",
    "## The number of items used in the iteration is retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"]\n",
    "ds_item.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## We get the slopes from the ALE data.\n",
    "for i in range(df.shape[1]-1):\n",
    "    structure_data = {'Question': ds_item.loc[i, \"Question\"]}\n",
    "    \n",
    "    for index in selection_class:\n",
    "        slope = proba_exp_lr.ale_values [i][1][index] - proba_exp_lr.ale_values [i][0][index]\n",
    "        structure_data['Slope ' + str(target_names[index])] = slope\n",
    "        structure_data['Threshold ' + str(target_names[index])] = 'NA'\n",
    "        structure_data['Anomaly ' + str(target_names[index])] = 'NA'\n",
    "        \n",
    "    dm = dm.append(structure_data, ignore_index=True)\n",
    "    \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdade16",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slope analysis and threshold application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb2418",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The slope obtained is analyzed and those that are above or below the positive and negative threshold are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b9ec68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## The slopes are selected according to the values of the thresholds of the defined classes.\n",
    "        if dm.loc[i, \"Slope \" + str(target_names[index])] >= positive_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 1\n",
    "        elif dm.loc[i, \"Slope \" + str(target_names[index])] <= negative_threshold:\n",
    "            dm.loc[i, \"Threshold \" + str(target_names[index])] = 0\n",
    "            \n",
    "## The current rating data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974164b8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis and determination of anomalous items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d771a5b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The anomalous items present in the model are determined based on their slope and expected response from the expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ed255e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The dataset of expected responses is loaded.\n",
    "da = pd.read_csv(path_dataset_qa)\n",
    "\n",
    "## Delete list of items deleted in this iteration.\n",
    "i = 0\n",
    "for x in ds_delete['Question']:\n",
    "    da.drop(da.index[x - (i + 1)], axis = 0, inplace = True)\n",
    "    i += 1\n",
    "\n",
    "## Indexes are restored for later use.\n",
    "da.reset_index(inplace=True, drop=True)\n",
    "\n",
    "## The dataset of expected responses is printed.\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3907eeb9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to identify the anomadic items present in the model present in this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba1d06",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[1]-1):\n",
    "    \n",
    "    ## Local variable to indicate the index of the selected classes.\n",
    "    i_index = 0\n",
    "    \n",
    "    for index in selection_class:\n",
    "        \n",
    "        ## Determine if it fails based on the expected response parameters of the defined classes.\n",
    "        if dm.loc[i, \"Threshold \"  + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][0]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 1 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][1]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 1:\n",
    "            dm.loc[i, \"Anomaly \" + str(target_names[index])] = expected_response_map[i_index][2]\n",
    "        if dm.loc[i, \"Threshold \" + str(target_names[index])] == 0 and da.loc[i, \"RE\"] == 0:\n",
    "            dm.loc[i, \"Anomaly \"  + str(target_names[index])] = expected_response_map[i_index][3]\n",
    "        \n",
    "        ## Increase of the index of the selected classes.\n",
    "        i_index += 1\n",
    "\n",
    "## The final grade data dataset is printed.\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefafadf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Removing identified anomadic items from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efb68b7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to eliminate the identified anomadic items so as not to use them in the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a39a2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variable for the elimination of the anomaly items.\n",
    "instructions = ''\n",
    "init = False\n",
    "question_anomaly = []\n",
    "\n",
    "if selection_mode == 1:\n",
    "    \n",
    "    ## Items that fail in the defined class are retrieved.\n",
    "    dm_delete = dm[dm['Anomaly ' + str(target_names[select_class_mode])] == 1]\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 2:\n",
    "    \n",
    "    ## Items that fail in classes defined with the or condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" or `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 3:\n",
    "    \n",
    "    ## Items that fail in classes defined with the and condition type are retrieved.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 1\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "    \n",
    "if selection_mode == 4:\n",
    "    \n",
    "    ## Out-of-threshold items are retrieved in classes defined with the condition type and.\n",
    "    for index in selection_class:\n",
    "        if init == False:\n",
    "            instructions += \"`Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "            init = True\n",
    "        else:\n",
    "            instructions += \" and `Anomaly \" + str(target_names[index]) + \"` == 'NA'\"\n",
    "    \n",
    "    dm_delete = dm.query(instructions)\n",
    "    dm_delete.reset_index(inplace=True, drop=True)\n",
    "    question_anomaly = dm_delete['Question'].tolist()\n",
    "\n",
    "## The selected blank items are printed according to the selection_mode.\n",
    "question_anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e5f3a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model explainability process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd4cce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data used for the test of the neural network model is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b78ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f493904b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7099b06",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In analysis of the model through the results obtained by ALE, it is possible to identify the behavior of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ab3cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The necessary parameters for the use of ALE are established according to the model.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aa5e7c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graphs of all the data present in the dataset used are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3709c411",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_ale(proba_exp_lr, n_cols=2, features=list(range(df.shape[1]-1)),fig_kw={'figwidth': 10, 'figheight': 180});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a849ae27",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12611cf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We proceed to explain the improved model using LIME for the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b4bfb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                   feature_names=train_cols, class_names=target_names, \n",
    "                                                   discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcf2db8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eaf949",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[0], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d88148",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680ada9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f3486",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d01824",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(X_test.to_numpy()[-1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f08186",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation of the model using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8060090",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SHAP explanatory values are displayed according to the class to which the selected individual belongs according to the prediction of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1223c0c8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first individual present in the test data is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde89c51",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[0]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c15fc4a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d3fc1",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42abf0b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The last individual present in the data test is explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a06dd",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Individual Selection.\n",
    "individual = X_test.iloc[[-1]]\n",
    "\n",
    "## Individual explanation by SHAP.\n",
    "explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "shap_values = explainer.shap_values(individual)\n",
    "clase = mlp.predict(individual)[0]\n",
    "shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f3f08",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanation using heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d102b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The importance of the data present in the neural network is shown from explanation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc36745",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Items currently in use are retrieved.\n",
    "ds_item = ds[ds.Status == \"In use\"].reset_index(drop=True)\n",
    "\n",
    "## The data is prepared for the generation of heatmaps.\n",
    "column_Map = ds_item['Question'].tolist()\n",
    "content_Map = [False for x in range(1, df.shape[1])]\n",
    "\n",
    "## The next items to be deleted will be marked.\n",
    "for index in range(0, len(content_Map)):\n",
    "    \n",
    "    if iteration == 0:\n",
    "        for delete in list_contr:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "    else:\n",
    "        for delete in question_anomaly:\n",
    "            if column_Map[index] == delete:\n",
    "                content_Map [index] = True\n",
    "\n",
    "## The dataframe is created with the prepared data.\n",
    "df_mask = pd.DataFrame([content_Map], columns = column_Map)\n",
    "df_mask_imp = pd.concat([df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "df_mask_all = pd.concat([df_mask, df_mask, df_mask, df_mask], ignore_index = True, axis = 0)\n",
    "\n",
    "df_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126b5e7c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48da240a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Identification of feature variables from the randomness of the answers as items of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a39788",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Loading the data for explainability.\n",
    "explainer = ClassifierExplainer(mlp, X_test, y_test)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a2f5ba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b794740",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee11537",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a882a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aef216",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded762e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "iterable_class += 1\n",
    "df_importance = explainer.permutation_importances(iterable_class).sort_index()\n",
    "df_importance.index = column_Map\n",
    "df_importance.drop(\"Score\",inplace=True, axis=1)\n",
    "df_importance.drop(\"Feature\",inplace=True, axis=1)\n",
    "df_importance.loc[df_importance['Importance'] < 0, 'Importance'] = 0\n",
    "map_class.append(df_importance)\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa0358",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ae91e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_importance = pd.concat(map_class, axis=1)\n",
    "df_importance.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Reds\", cbar = False)\n",
    "sns.heatmap(df_importance.transpose(), cmap = \"Blues\",yticklabels = True, xticklabels = True ,mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d1a01",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03797313",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86613754",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f412a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d4cb38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8b57d6",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3ce1e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5cc153",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a9bdb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d47909a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ac4555",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678949c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018eaa12",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b667c7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12625b37",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c78f8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4b367",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6090b2e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cde4d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0e2281",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32e535e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71c927",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ba8b70",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Definition of explainability data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638b8ec5",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "df_shap = explainer.get_shap_values_df(iterable_class)\n",
    "df_shap.columns = column_Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b16085",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8586e8b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,14))\n",
    "sns.heatmap(df_shap, cmap=\"vlag_r\", yticklabels=True, xticklabels=True, center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecffa9ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a9ab5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_shap_mean = df_shap.abs().mean(axis=0).to_frame()\n",
    "df_shap_mean.columns= [\"Mean SHAP\"]\n",
    "map_class.append(df_shap_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d288bda",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2d6c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b2f24c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612d959",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Fusion of the previous heatmaps.\n",
    "df_shap = pd.concat(map_class, axis=1)\n",
    "df_shap.columns = name_class\n",
    "\n",
    "## Generation of the heatmap.\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_shap.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045865c8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02232c3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Contribution in the final probability of each question for specific instances at the local level. For each class, a map is first shown with all the individuals and the contribution of each question, and then a map made with the mean of these values in absolute value. This seeks to globalize the scope of LIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af42ae9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data preparation for explainability.\n",
    "lime_exp = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                  feature_names=train_cols, class_names=target_names,\n",
    "                                                  discretize_continuous=True)\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b567bc39",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by LIME about the Low, Medium and High classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde32ad3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for LIME array data.\n",
    "exp_matrix = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for LIME.\n",
    "for x in X_test.to_numpy():\n",
    "    \n",
    "    ## Auxiliary temporary variables.\n",
    "    exp_list = [[] for _ in range(len(name_class))]\n",
    "    \n",
    "    ## Loading the data for explainability.\n",
    "    exp = lime_exp.explain_instance(x, mlp.predict_proba, num_features = df.shape[1] - 1, top_labels = len(name_class))\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "        temp = exp.as_map()[elements]\n",
    "        temp.sort(key=itemgetter(0))\n",
    "        \n",
    "        ## Saving data of the Low, Medium and High classes.\n",
    "        for tup in temp:\n",
    "            exp_list[elements].append(tup[1])\n",
    "            \n",
    "        exp_matrix[elements].append(exp_list[elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f6f71",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d01da96",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ee92a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4729369",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e7ea2",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8effb10",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee602e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758dd7f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d762c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c46af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc665f6f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Individual explainability of data belonging to the third class, in this case High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab92ac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec35fc0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,14))\n",
    "lime_df = pd.DataFrame(exp_matrix[iterable_class])\n",
    "lime_df.columns = column_Map\n",
    "sns.heatmap(lime_df, cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8512188c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b901ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lime_df_mean = lime_df.abs().mean(axis = 0).to_frame()\n",
    "lime_df_mean.columns= [\"Mean LIME\"]\n",
    "map_class.append(lime_df_mean)\n",
    "\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(map_class[iterable_class].transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True,\n",
    "            mask = df_mask.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af455703",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of all the class heatmaps into one map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7df780",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_lime = pd.concat(map_class, axis=1)\n",
    "df_lime.columns = name_class\n",
    "plt.figure(figsize = (32,6))\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_lime.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa138d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identification of feature variables using ALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ba162",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It shows the main effect of each question compared to the probability that the model predicts in each class. This effect is shown for both responses. Since there are only 2 answers, the map is the same but with the colors reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6604c672",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Definition of explainability data.\n",
    "proba_fun_lr = mlp.predict_proba\n",
    "proba_ale_lr = ALE(proba_fun_lr, feature_names=train_cols, target_names= target_names)\n",
    "proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())\n",
    "\n",
    "## Class index local variable.\n",
    "iterable_class = -1\n",
    "map_class = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8286dcc9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Obtaining the data for the generation of the explanations by ALE about all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d0da9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for ALE array data.\n",
    "ale_list = [[] for _ in range(len(name_class))]\n",
    "\n",
    "## Recovering the data needed for ALE.\n",
    "for array in proba_exp_lr.ale_values:\n",
    "    \n",
    "    ## Recovering the data.\n",
    "    for elements in range(0, len(name_class)):\n",
    "    \n",
    "        ## Saving data of all the classes.\n",
    "        ale_list[elements].append(array[0][elements])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce2fa57",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data processing for the explainability of ALE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245265e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data processing of the Low, Medium and High classes.\n",
    "for elements in range(0, len(name_class)):\n",
    "    ale_df = pd.DataFrame([ale_list [elements]])\n",
    "    ale_df = pd.concat([ale_df.multiply(-1), ale_df])\n",
    "    ale_df.index = [name_class [elements] + \" - False\", name_class [elements] + \" - True\"]\n",
    "    ale_df.columns = column_Map\n",
    "    map_class.append(ale_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f576626d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb087848",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f847a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73633d3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf060bf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3c431",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19a644",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Explainability of the data belonging to the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7820b50",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c851e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterable_class += 1\n",
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(map_class[iterable_class], cmap=\"vlag_r\",yticklabels=True, xticklabels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004fd3e7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fusion of the data used in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c343f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Application of absolute value to data.\n",
    "for index in range(0, len(map_class)):\n",
    "    map_class [index] = map_class [index][0:1].abs()\n",
    "\n",
    "## Union of the heatmaps of the Low, Medium and High class.\n",
    "ale_df = pd.concat(map_class)\n",
    "ale_df.index = name_class\n",
    "ale_df = ale_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d458669",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715cfa0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,6))\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(ale_df.transpose(), cmap=\"Blues\", yticklabels = True, xticklabels = True, mask= df_mask_imp.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f6cb5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Comparing of Feature Variables Methods for Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa6927",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The global values of each of the methods used are taken, their maximums are obtained (the minimums are 0) and a percentage is calculated based on said maximum, which indicates how relevant the contribution is for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f5e07c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Class index local variable.\n",
    "iterable_class = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decad4ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the first class, in this case the Low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792e1513",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c2eb8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c07e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e59a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907f0878",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616898a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2502eb8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the second class, in this case the Medium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f621cc53",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c5d53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05e1a92",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3573829",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df5e33",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee5e19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf65bcc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of the explanation methods of the third class, in this case the High."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f80616e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The highest data of each method used is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5797f43d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The maximum present value is obtained in each explainability method.\n",
    "iterable_class += 1\n",
    "max_importance = df_importance[name_class[iterable_class]].max()\n",
    "max_shap = df_shap[name_class[iterable_class]].max()\n",
    "max_lime = df_lime[name_class[iterable_class]].max()\n",
    "max_ale  = ale_df[name_class[iterable_class]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac36bf3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A new heatmap is created containing all the values of each method used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ba41b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## The values are calculated to plot the new heatmap.\n",
    "df_general = pd.DataFrame([df_importance[name_class[iterable_class]].multiply(100/max_importance), \n",
    "                            df_lime[name_class[iterable_class]].multiply(100/max_lime),  \n",
    "                            df_shap[name_class[iterable_class]].multiply(100/max_shap),\n",
    "                            ale_df[name_class[iterable_class]].multiply(100/max_ale)])\n",
    "\n",
    "## Method names are assigned.\n",
    "df_general.index = name_methods\n",
    "df_general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a466a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7e582",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (28,8))\n",
    "sns.heatmap(df_general, cmap=\"Reds\", cbar = False)\n",
    "sns.heatmap(df_general, cmap=\"Blues\", yticklabels = True, xticklabels = True, mask = df_mask_all.to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609864c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Safeguarding the items eliminated during this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c47e41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Removal of anomalous items selected by selection_mode.\n",
    "for x in question_anomaly:\n",
    "\n",
    "    ## Status change of the deleted items in the respective auxiliary dataset.\n",
    "    ds.loc[x - 1,'Status'] = 'Delete'\n",
    "\n",
    "## Save the changed statuses in the dataset.\n",
    "ds.to_csv(path_dataset_qs, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68129abe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation of final graphs from the results obtained by the improvement process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741f2187",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Different graphs are generated with the aim of clearly illustrating the data obtained from the model improvement process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9459e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Loading data from the dataset.\n",
    "df = pd.read_csv(path_dataset)\n",
    "dd = pd.read_csv(path_dataset_qd)\n",
    "\n",
    "## Eliminating physical-related items in dataset.\n",
    "df = df.drop(df.columns[102:-1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12748479",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "All the data necessary to generate the graphs are obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1a347",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Local variables for graph generation.\n",
    "total_question = []\n",
    "global_accuracy = []\n",
    "total_delete = []\n",
    "recalls = [[] for _ in range(len(name_class))]\n",
    "labels_plot = []\n",
    "\n",
    "## Get the total number of iterations.\n",
    "iterations = list(map(str, list(range(1, (dd.shape[0] + 1)))))\n",
    "\n",
    "## Obtaining data from the dataset.\n",
    "for x in range(dd.shape[0]):\n",
    "    \n",
    "    ## The total number of items used in each iteration is obtained.\n",
    "    total_question.append((df.shape[1] - 1) - len((dd.loc[x, 'Question']).split(',')))\n",
    "    \n",
    "    ## The global acurracy of each iteration is obtained.\n",
    "    global_accuracy.append((dd.loc[x, 'Acurracy global']) / 100)\n",
    "    \n",
    "    ## The total number of items eliminated in each iteration is obtained.\n",
    "    if x == 0:\n",
    "        total_delete.append(len((dd.loc[x, 'Question']).split(',')))\n",
    "    else:\n",
    "        total_delete.append(len((dd.loc[x, 'Question']).split(',')) - len((dd.loc[x - 1, 'Question']).split(',')))\n",
    "    \n",
    "    ## The recall of all classes of each iteration is obtained.\n",
    "    for index in range(0, len(name_class)):\n",
    "        recalls[index].append(dd.loc[x, 'Recall_' + str(index)])\n",
    "    \n",
    "for target in target_names:\n",
    "    labels_plot.append(target + \" Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01946731",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the graph of items used in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a347669",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Generation of the graph according to the data obtained.\n",
    "plt.figure()\n",
    "labels = ['Remaining questions']\n",
    "plt.title('Remaining questions over several item removal iterations')\n",
    "plt.plot(iterations, total_question, marker= 'o', color = 'blue')\n",
    "plt.ylabel(\"Remaining questions\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylim(0, df.shape[1] - 1)\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8c2287",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the graph of the acurracy obtained in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a089484",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Generation of the graph according to the data obtained.\n",
    "plt.figure()\n",
    "labels=['Accuracy']\n",
    "plt.title('Accuracy results obtained over several item removal iterations')\n",
    "plt.plot(iterations, global_accuracy, marker= 'o', color = 'red')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ad5cd4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generation of the graph of items eliminated in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a93a2ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Generation of the graph according to the data obtained.\n",
    "plt.figure()\n",
    "labels=['Anomalous questions']\n",
    "plt.title('Amount of anomalous questions obtained over iterations')\n",
    "plt.plot(iterations, total_delete, marker= 'o', color = 'green')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Anomalous questions\")\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af93c2d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graph is generated with the merger of the acurracy with the anomadic items eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6f5e0",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Generation of the graph according to the data obtained.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Accuracy', color = 'tab:red')\n",
    "ax.plot(iterations, global_accuracy, marker= 'o', color= 'tab:red')\n",
    "ax.tick_params(axis='y', labelcolor= 'tab:red')\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "ax = ax.twinx()  \n",
    "\n",
    "ax.set_ylabel('Anomalous Questions', color= 'tab:green')  \n",
    "ax.plot(iterations, total_delete, marker= '^', color= 'tab:green')\n",
    "ax.tick_params(axis='y', labelcolor= 'tab:green')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title('Accuracy and number of anomalous questions' +\n",
    "          'obtained over several item removal iterations')\n",
    "plt.xticks(range(0, iteration, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76760d9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graph is generated with the fusion of the recall obtained in the improvement process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca67eb",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Generation of the graph according to the data obtained.\n",
    "plt.figure()\n",
    "plt.title('Recall results obtained over several question removal iterations')\n",
    "for index in range(0, len(name_class)):\n",
    "    plt.plot(iterations, recalls[index], marker= 'o',\n",
    "             color = list_color[index])\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(labels_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beed98f4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graph is generated with the fusion of the recall and the eliminated items obtained in the improvement process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06118f2e",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Generation of the graph according to the data obtained.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Recall', color= 'tab:blue')\n",
    "for index in range(0, len(name_class)):\n",
    "    plt.plot(iterations, recalls[index], marker= 'o',\n",
    "             color = list_color[index])\n",
    "ax.tick_params(axis='y', labelcolor= 'tab:blue')\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(labels_plot)\n",
    "ax = ax.twinx()\n",
    "\n",
    "ax.set_ylabel('Anomalous Questions', color = 'tab:green')  \n",
    "ax.plot(iterations, total_delete, marker= '^', color = 'tab:green')\n",
    "ax.tick_params(axis='y', labelcolor = 'tab:green')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title('Recall results and anomalous question obtained ' +\n",
    "          'over several question removal iterations')\n",
    "plt.xticks(range(0, iteration, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f3f90",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}