{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd35c7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3369944167.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Asus User\\AppData\\Local\\Temp\\ipykernel_26772\\3369944167.py\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    def load_dataset_from_csv(self, dataset_csv, dependant_variables_range = [:-1], target_variable = [-1], target_names):\u001b[0m\n\u001b[1;37m                                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class IREX:\n",
    "    def __init__(self):\n",
    "        ## The names of the explanation methods used are defined.\n",
    "        name_methods = [\"Importance\", \"LIME\", \"SHAP\", \"ALE\"]\n",
    "\n",
    "    def load_dataset_from_csv(self, dataset_csv, dependant_variables_range = [0:-1], target_variable = [-1], target_names):\n",
    "        self.dataset_file = dataset_csv\n",
    "        self.df = pd.read_csv(path_dataset)\n",
    "        self.train_cols = df.columns.range(dependant_variables_range)\n",
    "        self.label = df.columns.range(target_variable)\n",
    "        self.X = df [self.train_cols]\n",
    "        self.y = df [self.label]\n",
    "        self.target_names = target_names\n",
    "    \n",
    "    def load_dataset(self, train_cols_dataframe, target_col_dataframe, target_names):\n",
    "        self.train_cols = train_cols_dataframe\n",
    "        self.label = target_col_dataframe\n",
    "        self.X = df [self.train_cols]\n",
    "        self.y = df [self.label] \n",
    "        self.target_names = target_names\n",
    "  \n",
    "    def load_expected_answers(csv_filename, item_column_index = 0, class_column_index = 1, expected_answer_index = 2):\n",
    "        #cargar scv y crear una función que devuelve el valor esperado dado el índice del item y la clase:\n",
    "        # el csv tiene: col0: item index, col1: class, col2: valoresperado\n",
    "        # def eaf(item,class): \n",
    "        self.eaf = eaf\n",
    "    \n",
    "    def set_expected_answers_function(function):\n",
    "        self.eaf = function\n",
    "    \n",
    "\n",
    "    def reset_IREX(self):\n",
    "        ## Generation of the question status list automatically.\n",
    "        question = list(range(1, self.train_cols.shape[1]))\n",
    "        status = ['In use' for _ in range(1, self.train_cols.shape[1])]\n",
    "        self.ds = pd.DataFrame({'Question': question, 'Status': status})\n",
    "\n",
    "        ## Save the changed statuses in the dataset.\n",
    "        self.ds.to_csv(path_dataset_qs, index = False)\n",
    "\n",
    "        ## Generation of the data structure by iteration automatically.\n",
    "        columns = ['Question', 'Acurracy global']\n",
    "\n",
    "        for index in range(0, len(name_class)):\n",
    "            columns.append('Precision_' + str(index))\n",
    "            columns.append('Recall_' + str(index))\n",
    "            columns.append('F1_score_' + str(index))\n",
    "            columns.append('Support_' + str(index))\n",
    "\n",
    "        self.dd = pd.DataFrame(columns = columns)\n",
    "\n",
    "        ## Save the changed data in the dataset.\n",
    "        self.dd.to_csv(path_dataset_qd, index = False)\n",
    "        \n",
    "        ## The number of iterations performed in the explanation is defined.\n",
    "        self.iteration = 0\n",
    "\n",
    "    def oversample():\n",
    "        ## The oversample function used is defined.\n",
    "        random_state = 13\n",
    "        oversample = SMOTE(random_state = random_state)\n",
    "        self.X, self.y = oversample.fit_resample(self.X, self.y)\n",
    "        \n",
    "    def train_model(do_oversample=true, test_size=0.33, hidden_layer_sizes = (10,), activation = 'logistic', solver = 'adam', alpha = 1, \n",
    "             learning_rate = 'constant', learning_rate_init = 0.0001, max_iter = 100000, random_state = 77):\n",
    "        if(do_oversample):\n",
    "            oversamplle()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size, random_state=seed)\n",
    "        ## The value of the alpha parameter is kept at 1 as well as the value of the seed of random_state at 77.\n",
    "        self.mlp = MLPClassifier(hidden_layer_sizes, activation, solver, alpha, \n",
    "             learning_rate , learning_rate_init, max_iter0, random_state)\n",
    "\n",
    "        ## We print the data of the final generated model.\n",
    "        self.mlp.fit(self.X_train, self.y_train)\n",
    "    \n",
    "    def dump_model(filename):\n",
    "        joblib.dump(self.mlp, filename)\n",
    "        \n",
    "    def load_model(filename):\n",
    "        self.mlp = return joblib.load(filename)\n",
    "    \n",
    "    def evaluate_model():\n",
    "        ## The data for the generation of the confession matrix are defined.\n",
    "        confusion_matrix = ConfusionMatrixDisplay.from_estimator(self.mlp, self.X_test, self.y_test, display_labels = target_names,\n",
    "                                                         cmap = plt.cm.Blues)\n",
    "        confusion_matrix.ax_.set_title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "        \n",
    "        ## The necessary detailed prediction is generated.\n",
    "        y_pred = mlp.predict(self.X_test)\n",
    "\n",
    "        ## The detailed statistics of the model are printed.\n",
    "        print(classification_report(self.y_test,y_pred))\n",
    "        \n",
    "    def compute_explanation(PAI_significance_thresold = .1):\n",
    "        self.iteration++\n",
    "        __run_ALE()\n",
    "        __run_LIME()\n",
    "        __run_SHAP()\n",
    "        __run_Feature_Importance()\n",
    "        __compute_PAI(PAI_significance_thresold, selection_method = 1)#no liarse con esto. Hacer el más sencillo\n",
    "       \n",
    "    def __run_ALE():\n",
    "        #rellenar\n",
    "        #In analysis of the model through the results obtained by ALE, it is possible to identify the behavior\n",
    "        #of the neural network.\n",
    "        ## The necessary parameters for the use of ALE are established according to the model.\n",
    "        proba_fun_lr = mlp.predict_proba\n",
    "        proba_ale_lr = ALE(proba_fun_lr, feature_names = train_cols, target_names = target_names)\n",
    "        proba_exp_lr = proba_ale_lr.explain(X_train.to_numpy())\n",
    "        plot_ale(proba_exp_lr, n_cols=2, features=list(range(df.shape[1]-1)),fig_kw={'figwidth': 10, 'figheight': 180});\n",
    "\n",
    "    def __run_LIME():\n",
    "        #rellenar\n",
    "        #We proceed to explain the improved model using LIME for the Low, Medium and High classes.\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), categorical_features=train_cols,\n",
    "                                                   feature_names=train_cols, class_names=target_names, \n",
    "                                                   discretize_continuous=True)\n",
    "        #The first individual present in the test data is explained.\n",
    "        exp = explainer.explain_instance(X_test.to_numpy()[0], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "        exp.show_in_notebook(show_table=True, show_all=False)\n",
    "        #The second individual present in the test data is explained.\n",
    "        exp = explainer.explain_instance(X_test.to_numpy()[1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "        exp.show_in_notebook(show_table=True, show_all=False)\n",
    "        #The last individual present in the test data is explained.\n",
    "        exp = explainer.explain_instance(X_test.to_numpy()[-1], mlp.predict_proba, num_features=6,top_labels=1) \n",
    "        exp.show_in_notebook(show_table=True, show_all=False)\n",
    "    def __run_SHAP():\n",
    "        #rellenar\n",
    "        #SHAP explanatory values are displayed according to the class to which the selected individual belongs according to the prediction of the model.\n",
    "        #The first individual present in the test data is explained.\n",
    "        ## Individual Selection.\n",
    "        individual = X_test.iloc[[0]]\n",
    "\n",
    "        ## Individual explanation by SHAP.\n",
    "        explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "        shap_values = explainer.shap_values(individual)\n",
    "        clase = mlp.predict(individual)[0]\n",
    "        shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")\n",
    "        #The second individual present in the data test is explained.\n",
    "        ## Individual Selection.\n",
    "        individual = X_test.iloc[[1]]\n",
    "\n",
    "        ## Individual explanation by SHAP.\n",
    "        explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "        shap_values = explainer.shap_values(individual)\n",
    "        clase = mlp.predict(individual)[0]\n",
    "        shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")\n",
    "        #The last individual present in the data test is explained.\n",
    "        ## Individual Selection.\n",
    "        individual = X_test.iloc[[-1]]\n",
    "\n",
    "        ## Individual explanation by SHAP.\n",
    "        explainer = shap.KernelExplainer(mlp.predict_proba, X_train,feature_names = train_cols, output_names = target_names)\n",
    "        shap_values = explainer.shap_values(individual)\n",
    "        clase = mlp.predict(individual)[0]\n",
    "        shap.summary_plot(shap_values[clase], individual, feature_names = train_cols, plot_type = \"bar\")\n",
    "    #def __run_Feature_Importance():\n",
    "        #rellenar\n",
    "    \n",
    "    #def __compute_PAI(selection_method = 1):\n",
    "        #rellenar\n",
    "        #según el número que pongan, es el método para determinar las PAIs (los 5 casos que nos dió juan)\n",
    "        \n",
    "    def visualize_global_heatmap(_class):\n",
    "        #según la clase, se tiene que visualizar el mapa de calor\n",
    "    \n",
    "    def visualize_class_heatmap(_class, XAI_method):\n",
    "        #según la clase que se elija y el método, se desplegará el mapa de calor solo de dicha clase\n",
    "        \n",
    "    def visualize_average_heatmap(XAI_method):\n",
    "        #\n",
    "    \n",
    "    def visualize_detailled_heatmap(XAI_method):\n",
    "        #\n",
    "        \n",
    "    def refine_dataset(anomalous_list):\n",
    "        # remove items from dataframes self.X self.y\n",
    "\n",
    "        \n",
    "    def plot_global_process(accuracy = true, precision = true, recall = true):\n",
    "        #todo\n",
    "        #depende de lo que elijan, que se despliegue el dato (aunque creo que con este codig no se puede)\n",
    "        #We get the detailed statistics of the final model.\n",
    "        ## The necessary detailed prediction is generated.\n",
    "        y_pred = mlp.predict(X_test)\n",
    "\n",
    "        ## The detailed statistics of the model are printed.\n",
    "        print('Classification accuracy =',accuracy_score(y_test,y_pred) * 100,'%\\n')\n",
    "        print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1fa9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "irex = new IREX()\n",
    "irex.load_dataset_from_csv('file.csv', [:-1], [-1], [\"Low\",\"Mid\",\"High\"])\n",
    "irex.load_expected_answers('answers.csv')\n",
    "irex.reset()\n",
    "irex.oversample()\n",
    "irex.train()\n",
    "irex.evaluate_model()\n",
    "irex.compute_explanation()\n",
    "irex.visualize_global_heatmap(\"High\")\n",
    "irex.visualize_class_heatmap(\"High\",\"LIME\")\n",
    "irex.refine_dataset([2,7,9,3,13,34])\n",
    "\n",
    "irex.train()\n",
    "irex.evaluate_model()\n",
    "irex.compute_explanation()\n",
    "irex.visualize_global_heatmap(\"High\")\n",
    "irex.visualize_class_heatmap(\"High\",\"LIME\")\n",
    "irex.refine_dataset([2,7,9,3,13,34])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
